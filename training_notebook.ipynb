{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9628f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.13/site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: yfinance in /opt/anaconda3/lib/python3.13/site-packages (0.2.66)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.13/site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.13/site-packages (1.13.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (4.57.3)\n",
      "Requirement already satisfied: peft in /opt/anaconda3/lib/python3.13/site-packages (0.18.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.13/site-packages (4.4.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: mcp in /opt/anaconda3/lib/python3.13/site-packages (1.23.1)\n",
      "Requirement already satisfied: google-generativeai in /opt/anaconda3/lib/python3.13/site-packages (0.8.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.13/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2.1.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (4.3.7)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (3.18.3)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (5.29.3)\n",
      "Requirement already satisfied: websockets>=13.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.13/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (4.23.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (2.6.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (2.12.5)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /opt/anaconda3/lib/python3.13/site-packages (from pyjwt[crypto]>=2.10.1->mcp) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (3.0.3)\n",
      "Requirement already satisfied: starlette>=0.27 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.50.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.38.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.11.0->mcp) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.11.0->mcp) (2.41.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/lib/python3.13/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.13/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic-settings>=2.5.2->mcp) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from pyjwt[crypto]>=2.10.1->mcp) (44.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.13/site-packages (from uvicorn>=0.31.1->mcp) (8.1.8)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /opt/anaconda3/lib/python3.13/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests yfinance sentence-transformers faiss-cpu transformers peft datasets torch mcp google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf3f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are Ready\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import faiss; import yfinance; print('We are Ready')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0c8ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SCRAPING FINANCE WIKIPEDIA ARTICLES\n",
      "======================================================================\n",
      "\n",
      "✓ Scraping: Stock\n",
      "  ✓ Success! 3865 chars\n",
      "\n",
      "✓ Scraping: Bond (finance)\n",
      "  ✓ Success! 4179 chars\n",
      "\n",
      "✓ Scraping: Government bond\n",
      "  ✓ Success! 3308 chars\n",
      "\n",
      "✓ Scraping: Corporate bond\n",
      "  ✓ Success! 3322 chars\n",
      "\n",
      "✓ Scraping: Fixed income\n",
      "  ✓ Success! 5364 chars\n",
      "\n",
      "✓ Scraping: Dividend\n",
      "  ✓ Success! 3861 chars\n",
      "\n",
      "✓ Scraping: Portfolio\n",
      "  ✓ Success! 23 chars\n",
      "\n",
      "✓ Scraping: Investment\n",
      "  ✓ Success! 1752 chars\n",
      "\n",
      "✓ Scraping: Risk management\n",
      "  ✓ Success! 4784 chars\n",
      "======================================================================\n",
      "SCRAPING FINANCE NEWS/INFO SITES\n",
      "======================================================================\n",
      "\n",
      "✓ Scraping: https://www.google.com/finance/markets\n",
      "  ✓ Success! 0 chars\n",
      "\n",
      "✓ Scraping: https://finance.yahoo.com/\n",
      "  ✓ Success! 788 chars\n",
      "\n",
      "✓ Scraping: https://www.investopedia.com/markets-news-4427782\n",
      "  ✓ Success! 0 chars\n",
      "\n",
      "✓ Scraping: https://www.marketwatch.com/\n",
      "  ✗ Error: status 401\n",
      "\n",
      "✓ Saved 12 documents to finance_knowledge_base.json\n"
     ]
    }
   ],
   "source": [
    "!python finance_wiki_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09213e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING HUGGING FACE FINANCE DATASET\n",
      "======================================================================\n",
      "Dataset : financial_phrasebank\n",
      "Subset  : sentences_allagree\n",
      "Split   : train\n",
      "Limit   : 500\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "✓ Loaded 500 documents from Hugging Face zip\n",
      "\n",
      "✓ Saved 500 documents to finance_knowledge_base.json\n"
     ]
    }
   ],
   "source": [
    "!python finance_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c29e6c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TASK 1: RAG PIPELINE WITH FINANCE DATA\n",
      "======================================================================\n",
      "\n",
      "1. Preparing curated finance QAs...\n",
      "   ✓ Loaded 10 curated QAs\n",
      "\n",
      "2. Creating embeddings over questions...\n",
      "   ✓ Created 10 embeddings\n",
      "\n",
      "3. Building FAISS index...\n",
      "   ✓ Index ready with 10 documents\n",
      "\n",
      "4. Answering via nearest curated QA...\n",
      "\n",
      "5. Testing RAG with finance questions...\n",
      "\n",
      "   Q: What is a stock?\n",
      "   A: A stock is a share of ownership in a company, giving the holder a claim on assets and earnings.\n",
      "\n",
      "   Q: What are bonds?\n",
      "   A: A bond is a loan to an issuer that pays interest and returns principal at maturity.\n",
      "\n",
      "   Q: What is dividend investing?\n",
      "   A: Dividend investing focuses on buying companies that pay regular dividends to shareholders.\n"
     ]
    }
   ],
   "source": [
    "!python finance_rag.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414d770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Preparing finance training data...\n",
      "   ✓ Created 500 QA-style training examples (from knowledge base if available)\n",
      "\n",
      "2. Tokenizing data...\n",
      "Map: 100%|██████████████████████████| 500/500 [00:00<00:00, 23398.66 examples/s]\n",
      "   ✓ Tokenized\n",
      "\n",
      "3. Loading base model...\n",
      "   ✓ Loaded distilgpt2\n",
      "\n",
      "4. Configuring LoRA...\n",
      "/opt/anaconda3/lib/python3.13/site-packages/peft/tuners/lora/layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "   ✓ LoRA configured\n",
      "   ✓ Trainable: 147,456 / 82,060,032 (0.18%)\n",
      "\n",
      "5. Training (this takes ~2 minutes)...\n",
      "  0%|                                                   | 0/750 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "{'loss': 5.8981, 'grad_norm': 0.9689181447029114, 'learning_rate': 4.993333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 5.6504, 'grad_norm': 0.8847298622131348, 'learning_rate': 4.9800000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 6.3822, 'grad_norm': 0.9905306100845337, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 6.0395, 'grad_norm': 0.7819933891296387, 'learning_rate': 4.9533333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 5.6907, 'grad_norm': 0.8347366452217102, 'learning_rate': 4.94e-05, 'epoch': 0.04}\n",
      "{'loss': 6.1192, 'grad_norm': 1.119035243988037, 'learning_rate': 4.926666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 5.8468, 'grad_norm': 1.117051362991333, 'learning_rate': 4.913333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 5.9298, 'grad_norm': 1.27223801612854, 'learning_rate': 4.9e-05, 'epoch': 0.06}\n",
      "{'loss': 5.9991, 'grad_norm': 1.1969634294509888, 'learning_rate': 4.886666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 5.3155, 'grad_norm': 1.0558263063430786, 'learning_rate': 4.8733333333333337e-05, 'epoch': 0.08}\n",
      "{'loss': 5.5987, 'grad_norm': 1.2036106586456299, 'learning_rate': 4.86e-05, 'epoch': 0.09}\n",
      "{'loss': 6.0335, 'grad_norm': 0.9486238360404968, 'learning_rate': 4.8466666666666675e-05, 'epoch': 0.1}\n",
      "{'loss': 5.702, 'grad_norm': 1.6843006610870361, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.1}\n",
      "{'loss': 5.6177, 'grad_norm': 0.9978311061859131, 'learning_rate': 4.82e-05, 'epoch': 0.11}\n",
      "{'loss': 5.1595, 'grad_norm': 1.150017261505127, 'learning_rate': 4.806666666666667e-05, 'epoch': 0.12}\n",
      "{'loss': 6.1598, 'grad_norm': 1.4361529350280762, 'learning_rate': 4.793333333333334e-05, 'epoch': 0.13}\n",
      "{'loss': 5.9126, 'grad_norm': 1.245903730392456, 'learning_rate': 4.78e-05, 'epoch': 0.14}\n",
      "{'loss': 5.2883, 'grad_norm': 1.3107744455337524, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.14}\n",
      "{'loss': 5.754, 'grad_norm': 1.3589457273483276, 'learning_rate': 4.7533333333333334e-05, 'epoch': 0.15}\n",
      "{'loss': 5.4, 'grad_norm': 1.4607511758804321, 'learning_rate': 4.74e-05, 'epoch': 0.16}\n",
      "{'loss': 5.5739, 'grad_norm': 1.2439091205596924, 'learning_rate': 4.726666666666667e-05, 'epoch': 0.17}\n",
      "{'loss': 5.2122, 'grad_norm': 1.2068898677825928, 'learning_rate': 4.713333333333333e-05, 'epoch': 0.18}\n",
      "{'loss': 5.8913, 'grad_norm': 1.3747822046279907, 'learning_rate': 4.7e-05, 'epoch': 0.18}\n",
      "{'loss': 5.3381, 'grad_norm': 1.3050113916397095, 'learning_rate': 4.686666666666667e-05, 'epoch': 0.19}\n",
      "{'loss': 5.3696, 'grad_norm': 1.7455888986587524, 'learning_rate': 4.6733333333333335e-05, 'epoch': 0.2}\n",
      "{'loss': 5.1107, 'grad_norm': 1.4422527551651, 'learning_rate': 4.660000000000001e-05, 'epoch': 0.21}\n",
      "{'loss': 6.2365, 'grad_norm': 1.4087461233139038, 'learning_rate': 4.646666666666667e-05, 'epoch': 0.22}\n",
      "{'loss': 5.8965, 'grad_norm': 2.0896098613739014, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.22}\n",
      "{'loss': 4.4559, 'grad_norm': 1.130340814590454, 'learning_rate': 4.6200000000000005e-05, 'epoch': 0.23}\n",
      "{'loss': 5.587, 'grad_norm': 1.6963739395141602, 'learning_rate': 4.606666666666667e-05, 'epoch': 0.24}\n",
      "{'loss': 5.4551, 'grad_norm': 1.914986252784729, 'learning_rate': 4.5933333333333336e-05, 'epoch': 0.25}\n",
      "{'loss': 4.7215, 'grad_norm': 1.245301604270935, 'learning_rate': 4.58e-05, 'epoch': 0.26}\n",
      "{'loss': 4.9645, 'grad_norm': 1.0863301753997803, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.26}\n",
      "{'loss': 5.8426, 'grad_norm': 1.5982433557510376, 'learning_rate': 4.553333333333333e-05, 'epoch': 0.27}\n",
      "{'loss': 5.6625, 'grad_norm': 1.7129943370819092, 'learning_rate': 4.5400000000000006e-05, 'epoch': 0.28}\n",
      "{'loss': 4.8103, 'grad_norm': 1.4542003870010376, 'learning_rate': 4.526666666666667e-05, 'epoch': 0.29}\n",
      "{'loss': 5.1463, 'grad_norm': 2.416501998901367, 'learning_rate': 4.513333333333333e-05, 'epoch': 0.3}\n",
      "{'loss': 5.4818, 'grad_norm': 2.443394660949707, 'learning_rate': 4.5e-05, 'epoch': 0.3}\n",
      "{'loss': 5.7512, 'grad_norm': 2.1543431282043457, 'learning_rate': 4.486666666666667e-05, 'epoch': 0.31}\n",
      "{'loss': 5.3236, 'grad_norm': 1.7690551280975342, 'learning_rate': 4.473333333333334e-05, 'epoch': 0.32}\n",
      "{'loss': 5.3487, 'grad_norm': 1.651853322982788, 'learning_rate': 4.46e-05, 'epoch': 0.33}\n",
      "{'loss': 6.1605, 'grad_norm': 1.9227306842803955, 'learning_rate': 4.4466666666666666e-05, 'epoch': 0.34}\n",
      "{'loss': 5.4236, 'grad_norm': 1.5295462608337402, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.34}\n",
      "{'loss': 5.5141, 'grad_norm': 2.077441453933716, 'learning_rate': 4.4200000000000004e-05, 'epoch': 0.35}\n",
      "{'loss': 5.0616, 'grad_norm': 1.668832778930664, 'learning_rate': 4.406666666666667e-05, 'epoch': 0.36}\n",
      "{'loss': 5.391, 'grad_norm': 1.5087286233901978, 'learning_rate': 4.3933333333333335e-05, 'epoch': 0.37}\n",
      "{'loss': 5.3254, 'grad_norm': 1.5988324880599976, 'learning_rate': 4.38e-05, 'epoch': 0.38}\n",
      "{'loss': 5.1168, 'grad_norm': 2.279468297958374, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.38}\n",
      "{'loss': 5.3009, 'grad_norm': 2.124974489212036, 'learning_rate': 4.353333333333334e-05, 'epoch': 0.39}\n",
      "{'loss': 5.112, 'grad_norm': 1.72225821018219, 'learning_rate': 4.3400000000000005e-05, 'epoch': 0.4}\n",
      "{'loss': 4.9313, 'grad_norm': 1.4810562133789062, 'learning_rate': 4.3266666666666664e-05, 'epoch': 0.41}\n",
      "{'loss': 5.3548, 'grad_norm': 2.1251461505889893, 'learning_rate': 4.3133333333333336e-05, 'epoch': 0.42}\n",
      "{'loss': 4.7435, 'grad_norm': 2.0463027954101562, 'learning_rate': 4.3e-05, 'epoch': 0.42}\n",
      "{'loss': 5.19, 'grad_norm': 1.8229279518127441, 'learning_rate': 4.286666666666667e-05, 'epoch': 0.43}\n",
      "{'loss': 5.246, 'grad_norm': 2.2781498432159424, 'learning_rate': 4.273333333333333e-05, 'epoch': 0.44}\n",
      "{'loss': 5.0765, 'grad_norm': 1.810945987701416, 'learning_rate': 4.26e-05, 'epoch': 0.45}\n",
      "{'loss': 4.9665, 'grad_norm': 1.7966203689575195, 'learning_rate': 4.246666666666667e-05, 'epoch': 0.46}\n",
      "{'loss': 5.1841, 'grad_norm': 2.1373848915100098, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.46}\n",
      "{'loss': 4.9317, 'grad_norm': 1.8654721975326538, 'learning_rate': 4.22e-05, 'epoch': 0.47}\n",
      "{'loss': 5.3578, 'grad_norm': 2.0184502601623535, 'learning_rate': 4.206666666666667e-05, 'epoch': 0.48}\n",
      "{'loss': 5.0628, 'grad_norm': 1.9573618173599243, 'learning_rate': 4.1933333333333334e-05, 'epoch': 0.49}\n",
      "{'loss': 4.7835, 'grad_norm': 1.7910693883895874, 'learning_rate': 4.18e-05, 'epoch': 0.5}\n",
      "{'loss': 4.9034, 'grad_norm': 2.7774133682250977, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n",
      "{'loss': 4.9283, 'grad_norm': 2.104705810546875, 'learning_rate': 4.153333333333334e-05, 'epoch': 0.51}\n",
      "{'loss': 5.295, 'grad_norm': 2.5182981491088867, 'learning_rate': 4.14e-05, 'epoch': 0.52}\n",
      "{'loss': 5.4857, 'grad_norm': 2.049306869506836, 'learning_rate': 4.126666666666667e-05, 'epoch': 0.53}\n",
      "{'loss': 4.9379, 'grad_norm': 2.509363889694214, 'learning_rate': 4.1133333333333335e-05, 'epoch': 0.54}\n",
      "{'loss': 4.5389, 'grad_norm': 1.9902782440185547, 'learning_rate': 4.1e-05, 'epoch': 0.54}\n",
      "{'loss': 4.8994, 'grad_norm': 2.148350954055786, 'learning_rate': 4.086666666666667e-05, 'epoch': 0.55}\n",
      "{'loss': 5.1381, 'grad_norm': 1.9729714393615723, 'learning_rate': 4.073333333333333e-05, 'epoch': 0.56}\n",
      "{'loss': 4.8138, 'grad_norm': 2.054262161254883, 'learning_rate': 4.0600000000000004e-05, 'epoch': 0.57}\n",
      "{'loss': 5.4618, 'grad_norm': 1.9266948699951172, 'learning_rate': 4.046666666666667e-05, 'epoch': 0.58}\n",
      "{'loss': 4.5708, 'grad_norm': 1.8320530652999878, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.58}\n",
      "{'loss': 5.2588, 'grad_norm': 2.1827237606048584, 'learning_rate': 4.02e-05, 'epoch': 0.59}\n",
      "{'loss': 4.9808, 'grad_norm': 2.1985063552856445, 'learning_rate': 4.006666666666667e-05, 'epoch': 0.6}\n",
      "{'loss': 5.2209, 'grad_norm': 2.022261142730713, 'learning_rate': 3.993333333333333e-05, 'epoch': 0.61}\n",
      "{'loss': 4.6634, 'grad_norm': 2.762517213821411, 'learning_rate': 3.9800000000000005e-05, 'epoch': 0.62}\n",
      "{'loss': 4.4865, 'grad_norm': 2.201183795928955, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.62}\n",
      "{'loss': 4.8091, 'grad_norm': 1.9993531703948975, 'learning_rate': 3.9533333333333337e-05, 'epoch': 0.63}\n",
      "{'loss': 4.6572, 'grad_norm': 2.272759199142456, 'learning_rate': 3.94e-05, 'epoch': 0.64}\n",
      "{'loss': 4.7057, 'grad_norm': 2.3539834022521973, 'learning_rate': 3.926666666666667e-05, 'epoch': 0.65}\n",
      "{'loss': 4.4141, 'grad_norm': 2.220458984375, 'learning_rate': 3.9133333333333334e-05, 'epoch': 0.66}\n",
      "{'loss': 4.885, 'grad_norm': 1.5889657735824585, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.66}\n",
      "{'loss': 4.4642, 'grad_norm': 2.296736001968384, 'learning_rate': 3.8866666666666665e-05, 'epoch': 0.67}\n",
      "{'loss': 4.6996, 'grad_norm': 1.8550913333892822, 'learning_rate': 3.873333333333333e-05, 'epoch': 0.68}\n",
      "{'loss': 4.5558, 'grad_norm': 1.9798041582107544, 'learning_rate': 3.86e-05, 'epoch': 0.69}\n",
      "{'loss': 4.1867, 'grad_norm': 2.804178476333618, 'learning_rate': 3.846666666666667e-05, 'epoch': 0.7}\n",
      "{'loss': 4.8501, 'grad_norm': 2.5809760093688965, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.7}\n",
      "{'loss': 4.8389, 'grad_norm': 2.6697704792022705, 'learning_rate': 3.82e-05, 'epoch': 0.71}\n",
      "{'loss': 4.3935, 'grad_norm': 2.196754217147827, 'learning_rate': 3.8066666666666666e-05, 'epoch': 0.72}\n",
      "{'loss': 4.4007, 'grad_norm': 3.283151388168335, 'learning_rate': 3.793333333333334e-05, 'epoch': 0.73}\n",
      "{'loss': 4.6648, 'grad_norm': 1.7589771747589111, 'learning_rate': 3.7800000000000004e-05, 'epoch': 0.74}\n",
      "{'loss': 4.741, 'grad_norm': 1.7218819856643677, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.74}\n",
      "{'loss': 4.698, 'grad_norm': 2.711686849594116, 'learning_rate': 3.7533333333333335e-05, 'epoch': 0.75}\n",
      "{'loss': 4.746, 'grad_norm': 3.1571807861328125, 'learning_rate': 3.74e-05, 'epoch': 0.76}\n",
      "{'loss': 4.8597, 'grad_norm': 2.512786388397217, 'learning_rate': 3.726666666666667e-05, 'epoch': 0.77}\n",
      "{'loss': 5.1056, 'grad_norm': 2.7987518310546875, 'learning_rate': 3.713333333333334e-05, 'epoch': 0.78}\n",
      "{'loss': 4.962, 'grad_norm': 2.765948534011841, 'learning_rate': 3.7e-05, 'epoch': 0.78}\n",
      "{'loss': 4.1123, 'grad_norm': 2.4130074977874756, 'learning_rate': 3.6866666666666664e-05, 'epoch': 0.79}\n",
      "{'loss': 4.4116, 'grad_norm': 3.087930679321289, 'learning_rate': 3.6733333333333336e-05, 'epoch': 0.8}\n",
      "{'loss': 4.1586, 'grad_norm': 2.5259158611297607, 'learning_rate': 3.66e-05, 'epoch': 0.81}\n",
      "{'loss': 4.5744, 'grad_norm': 2.4747064113616943, 'learning_rate': 3.646666666666667e-05, 'epoch': 0.82}\n",
      "{'loss': 4.4686, 'grad_norm': 3.9652976989746094, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.82}\n",
      "{'loss': 4.3066, 'grad_norm': 2.473834991455078, 'learning_rate': 3.62e-05, 'epoch': 0.83}\n",
      "{'loss': 4.6699, 'grad_norm': 2.5379421710968018, 'learning_rate': 3.606666666666667e-05, 'epoch': 0.84}\n",
      "{'loss': 3.8795, 'grad_norm': 2.286975860595703, 'learning_rate': 3.593333333333334e-05, 'epoch': 0.85}\n",
      "{'loss': 3.8336, 'grad_norm': 3.6870551109313965, 'learning_rate': 3.58e-05, 'epoch': 0.86}\n",
      "{'loss': 4.1639, 'grad_norm': 2.9542596340179443, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.86}\n",
      "{'loss': 4.8365, 'grad_norm': 2.3127193450927734, 'learning_rate': 3.5533333333333334e-05, 'epoch': 0.87}\n",
      "{'loss': 4.6634, 'grad_norm': 2.3543472290039062, 'learning_rate': 3.54e-05, 'epoch': 0.88}\n",
      "{'loss': 4.0065, 'grad_norm': 2.5445520877838135, 'learning_rate': 3.526666666666667e-05, 'epoch': 0.89}\n",
      "{'loss': 3.8957, 'grad_norm': 3.4858999252319336, 'learning_rate': 3.513333333333334e-05, 'epoch': 0.9}\n",
      "{'loss': 4.5586, 'grad_norm': 2.551133394241333, 'learning_rate': 3.5e-05, 'epoch': 0.9}\n",
      "{'loss': 4.1233, 'grad_norm': 3.0445494651794434, 'learning_rate': 3.486666666666667e-05, 'epoch': 0.91}\n",
      "{'loss': 3.8876, 'grad_norm': 3.148303747177124, 'learning_rate': 3.4733333333333335e-05, 'epoch': 0.92}\n",
      "{'loss': 3.9173, 'grad_norm': 3.670475482940674, 'learning_rate': 3.46e-05, 'epoch': 0.93}\n",
      "{'loss': 4.3826, 'grad_norm': 3.421837568283081, 'learning_rate': 3.4466666666666666e-05, 'epoch': 0.94}\n",
      "{'loss': 4.5479, 'grad_norm': 2.816041946411133, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.94}\n",
      "{'loss': 3.9763, 'grad_norm': 3.5080604553222656, 'learning_rate': 3.4200000000000005e-05, 'epoch': 0.95}\n",
      "{'loss': 4.422, 'grad_norm': 2.7085530757904053, 'learning_rate': 3.406666666666667e-05, 'epoch': 0.96}\n",
      "{'loss': 3.4995, 'grad_norm': 3.1237850189208984, 'learning_rate': 3.3933333333333336e-05, 'epoch': 0.97}\n",
      "{'loss': 4.4544, 'grad_norm': 2.2260396480560303, 'learning_rate': 3.38e-05, 'epoch': 0.98}\n",
      "{'loss': 4.5068, 'grad_norm': 2.4412407875061035, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.98}\n",
      "{'loss': 4.0463, 'grad_norm': 3.383466958999634, 'learning_rate': 3.353333333333333e-05, 'epoch': 0.99}\n",
      "{'loss': 4.0218, 'grad_norm': 3.8008296489715576, 'learning_rate': 3.3400000000000005e-05, 'epoch': 1.0}\n",
      " 33%|█████████████▋                           | 250/750 [00:23<00:45, 11.05it/s]/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 3.9552, 'grad_norm': 3.1197304725646973, 'learning_rate': 3.326666666666667e-05, 'epoch': 1.01}\n",
      "{'loss': 3.8905, 'grad_norm': 3.358705759048462, 'learning_rate': 3.313333333333333e-05, 'epoch': 1.02}\n",
      "{'loss': 4.4385, 'grad_norm': 2.9142072200775146, 'learning_rate': 3.3e-05, 'epoch': 1.02}\n",
      "{'loss': 4.159, 'grad_norm': 2.819835901260376, 'learning_rate': 3.286666666666667e-05, 'epoch': 1.03}\n",
      "{'loss': 3.6925, 'grad_norm': 3.9871373176574707, 'learning_rate': 3.2733333333333334e-05, 'epoch': 1.04}\n",
      "{'loss': 4.5282, 'grad_norm': 3.3037984371185303, 'learning_rate': 3.26e-05, 'epoch': 1.05}\n",
      "{'loss': 3.9637, 'grad_norm': 2.4531478881835938, 'learning_rate': 3.2466666666666665e-05, 'epoch': 1.06}\n",
      "{'loss': 4.228, 'grad_norm': 3.1301653385162354, 'learning_rate': 3.233333333333333e-05, 'epoch': 1.06}\n",
      "{'loss': 3.9432, 'grad_norm': 3.780409812927246, 'learning_rate': 3.2200000000000003e-05, 'epoch': 1.07}\n",
      "{'loss': 3.7045, 'grad_norm': 3.481257915496826, 'learning_rate': 3.206666666666667e-05, 'epoch': 1.08}\n",
      "{'loss': 4.3092, 'grad_norm': 3.379045009613037, 'learning_rate': 3.1933333333333335e-05, 'epoch': 1.09}\n",
      "{'loss': 3.5196, 'grad_norm': 3.532317638397217, 'learning_rate': 3.18e-05, 'epoch': 1.1}\n",
      "{'loss': 4.1636, 'grad_norm': 2.419734477996826, 'learning_rate': 3.1666666666666666e-05, 'epoch': 1.1}\n",
      "{'loss': 3.5703, 'grad_norm': 3.109246253967285, 'learning_rate': 3.153333333333334e-05, 'epoch': 1.11}\n",
      "{'loss': 3.6676, 'grad_norm': 3.595566987991333, 'learning_rate': 3.1400000000000004e-05, 'epoch': 1.12}\n",
      "{'loss': 3.735, 'grad_norm': 3.2199275493621826, 'learning_rate': 3.126666666666666e-05, 'epoch': 1.13}\n",
      "{'loss': 4.0388, 'grad_norm': 5.979281425476074, 'learning_rate': 3.1133333333333336e-05, 'epoch': 1.14}\n",
      "{'loss': 4.4713, 'grad_norm': 2.756709098815918, 'learning_rate': 3.1e-05, 'epoch': 1.14}\n",
      "{'loss': 3.3262, 'grad_norm': 4.445791721343994, 'learning_rate': 3.086666666666667e-05, 'epoch': 1.15}\n",
      "{'loss': 4.1848, 'grad_norm': 4.125211715698242, 'learning_rate': 3.073333333333334e-05, 'epoch': 1.16}\n",
      "{'loss': 3.6844, 'grad_norm': 3.255150079727173, 'learning_rate': 3.06e-05, 'epoch': 1.17}\n",
      "{'loss': 3.8906, 'grad_norm': 4.042588233947754, 'learning_rate': 3.0466666666666664e-05, 'epoch': 1.18}\n",
      "{'loss': 2.8973, 'grad_norm': 4.4772138595581055, 'learning_rate': 3.0333333333333337e-05, 'epoch': 1.18}\n",
      "{'loss': 3.7109, 'grad_norm': 4.3969292640686035, 'learning_rate': 3.02e-05, 'epoch': 1.19}\n",
      "{'loss': 3.6998, 'grad_norm': 3.200390100479126, 'learning_rate': 3.006666666666667e-05, 'epoch': 1.2}\n",
      "{'loss': 3.4535, 'grad_norm': 4.460817337036133, 'learning_rate': 2.9933333333333337e-05, 'epoch': 1.21}\n",
      "{'loss': 3.7705, 'grad_norm': 4.055151462554932, 'learning_rate': 2.98e-05, 'epoch': 1.22}\n",
      "{'loss': 3.6415, 'grad_norm': 4.466001033782959, 'learning_rate': 2.9666666666666672e-05, 'epoch': 1.22}\n",
      "{'loss': 3.6942, 'grad_norm': 3.2178714275360107, 'learning_rate': 2.9533333333333334e-05, 'epoch': 1.23}\n",
      "{'loss': 3.3864, 'grad_norm': 4.215050220489502, 'learning_rate': 2.94e-05, 'epoch': 1.24}\n",
      "{'loss': 4.1123, 'grad_norm': 2.736081123352051, 'learning_rate': 2.926666666666667e-05, 'epoch': 1.25}\n",
      "{'loss': 4.1508, 'grad_norm': 3.8101134300231934, 'learning_rate': 2.9133333333333334e-05, 'epoch': 1.26}\n",
      "{'loss': 3.7772, 'grad_norm': 4.213975429534912, 'learning_rate': 2.9e-05, 'epoch': 1.26}\n",
      "{'loss': 3.6898, 'grad_norm': 3.66760516166687, 'learning_rate': 2.886666666666667e-05, 'epoch': 1.27}\n",
      "{'loss': 3.6173, 'grad_norm': 3.400686025619507, 'learning_rate': 2.8733333333333335e-05, 'epoch': 1.28}\n",
      "{'loss': 3.9803, 'grad_norm': 3.471680164337158, 'learning_rate': 2.86e-05, 'epoch': 1.29}\n",
      "{'loss': 4.0773, 'grad_norm': 3.7849373817443848, 'learning_rate': 2.846666666666667e-05, 'epoch': 1.3}\n",
      "{'loss': 4.3454, 'grad_norm': 7.56604528427124, 'learning_rate': 2.8333333333333335e-05, 'epoch': 1.3}\n",
      "{'loss': 3.7572, 'grad_norm': 3.6152546405792236, 'learning_rate': 2.8199999999999998e-05, 'epoch': 1.31}\n",
      "{'loss': 2.7561, 'grad_norm': 4.7673516273498535, 'learning_rate': 2.806666666666667e-05, 'epoch': 1.32}\n",
      "{'loss': 3.9344, 'grad_norm': 2.5642833709716797, 'learning_rate': 2.7933333333333332e-05, 'epoch': 1.33}\n",
      "{'loss': 3.3698, 'grad_norm': 3.0609371662139893, 'learning_rate': 2.7800000000000005e-05, 'epoch': 1.34}\n",
      "{'loss': 3.211, 'grad_norm': 4.303725719451904, 'learning_rate': 2.7666666666666667e-05, 'epoch': 1.34}\n",
      "{'loss': 3.3956, 'grad_norm': 3.656423807144165, 'learning_rate': 2.7533333333333333e-05, 'epoch': 1.35}\n",
      "{'loss': 3.8178, 'grad_norm': 3.7724268436431885, 'learning_rate': 2.7400000000000002e-05, 'epoch': 1.36}\n",
      "{'loss': 3.7402, 'grad_norm': 3.1490988731384277, 'learning_rate': 2.7266666666666668e-05, 'epoch': 1.37}\n",
      "{'loss': 4.0154, 'grad_norm': 4.090330600738525, 'learning_rate': 2.7133333333333333e-05, 'epoch': 1.38}\n",
      "{'loss': 3.762, 'grad_norm': 5.058389663696289, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.38}\n",
      "{'loss': 4.1614, 'grad_norm': 3.9125888347625732, 'learning_rate': 2.6866666666666668e-05, 'epoch': 1.39}\n",
      "{'loss': 3.0406, 'grad_norm': 5.675264835357666, 'learning_rate': 2.6733333333333334e-05, 'epoch': 1.4}\n",
      "{'loss': 3.7666, 'grad_norm': 4.562155723571777, 'learning_rate': 2.6600000000000003e-05, 'epoch': 1.41}\n",
      "{'loss': 3.5319, 'grad_norm': 3.412688970565796, 'learning_rate': 2.646666666666667e-05, 'epoch': 1.42}\n",
      "{'loss': 3.9328, 'grad_norm': 3.1862246990203857, 'learning_rate': 2.633333333333333e-05, 'epoch': 1.42}\n",
      "{'loss': 2.8222, 'grad_norm': 4.341391086578369, 'learning_rate': 2.6200000000000003e-05, 'epoch': 1.43}\n",
      "{'loss': 3.5119, 'grad_norm': 3.8932929039001465, 'learning_rate': 2.6066666666666666e-05, 'epoch': 1.44}\n",
      "{'loss': 3.193, 'grad_norm': 2.930690050125122, 'learning_rate': 2.5933333333333338e-05, 'epoch': 1.45}\n",
      "{'loss': 3.1526, 'grad_norm': 3.841254472732544, 'learning_rate': 2.58e-05, 'epoch': 1.46}\n",
      "{'loss': 2.6911, 'grad_norm': 4.251628398895264, 'learning_rate': 2.5666666666666666e-05, 'epoch': 1.46}\n",
      "{'loss': 3.9219, 'grad_norm': 3.3720576763153076, 'learning_rate': 2.553333333333334e-05, 'epoch': 1.47}\n",
      "{'loss': 3.2337, 'grad_norm': 3.413785696029663, 'learning_rate': 2.54e-05, 'epoch': 1.48}\n",
      "{'loss': 3.0424, 'grad_norm': 3.21325945854187, 'learning_rate': 2.5266666666666666e-05, 'epoch': 1.49}\n",
      "{'loss': 3.8988, 'grad_norm': 3.7704856395721436, 'learning_rate': 2.5133333333333336e-05, 'epoch': 1.5}\n",
      "{'loss': 3.9194, 'grad_norm': 6.415533542633057, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n",
      "{'loss': 4.0406, 'grad_norm': 2.7670915126800537, 'learning_rate': 2.486666666666667e-05, 'epoch': 1.51}\n",
      "{'loss': 3.2758, 'grad_norm': 3.3347113132476807, 'learning_rate': 2.4733333333333333e-05, 'epoch': 1.52}\n",
      "{'loss': 3.7359, 'grad_norm': 3.9210362434387207, 'learning_rate': 2.46e-05, 'epoch': 1.53}\n",
      "{'loss': 3.0675, 'grad_norm': 4.697299957275391, 'learning_rate': 2.4466666666666667e-05, 'epoch': 1.54}\n",
      "{'loss': 3.7737, 'grad_norm': 2.779932737350464, 'learning_rate': 2.4333333333333336e-05, 'epoch': 1.54}\n",
      "{'loss': 2.9435, 'grad_norm': 6.265202045440674, 'learning_rate': 2.4200000000000002e-05, 'epoch': 1.55}\n",
      "{'loss': 3.7048, 'grad_norm': 3.4684805870056152, 'learning_rate': 2.4066666666666668e-05, 'epoch': 1.56}\n",
      "{'loss': 3.7321, 'grad_norm': 3.7108030319213867, 'learning_rate': 2.3933333333333337e-05, 'epoch': 1.57}\n",
      "{'loss': 2.7121, 'grad_norm': 3.7047462463378906, 'learning_rate': 2.38e-05, 'epoch': 1.58}\n",
      "{'loss': 3.1972, 'grad_norm': 3.9799015522003174, 'learning_rate': 2.3666666666666668e-05, 'epoch': 1.58}\n",
      "{'loss': 3.4629, 'grad_norm': 2.931042194366455, 'learning_rate': 2.3533333333333334e-05, 'epoch': 1.59}\n",
      "{'loss': 3.5604, 'grad_norm': 3.362765073776245, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.6}\n",
      "{'loss': 2.6432, 'grad_norm': 3.1677608489990234, 'learning_rate': 2.326666666666667e-05, 'epoch': 1.61}\n",
      "{'loss': 3.4, 'grad_norm': 4.5608367919921875, 'learning_rate': 2.3133333333333334e-05, 'epoch': 1.62}\n",
      "{'loss': 3.7285, 'grad_norm': 7.597506046295166, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.62}\n",
      "{'loss': 3.8081, 'grad_norm': 4.902161598205566, 'learning_rate': 2.2866666666666666e-05, 'epoch': 1.63}\n",
      "{'loss': 3.4468, 'grad_norm': 3.9007294178009033, 'learning_rate': 2.2733333333333335e-05, 'epoch': 1.64}\n",
      "{'loss': 3.3836, 'grad_norm': 4.250796318054199, 'learning_rate': 2.26e-05, 'epoch': 1.65}\n",
      "{'loss': 4.0927, 'grad_norm': 2.8132519721984863, 'learning_rate': 2.2466666666666666e-05, 'epoch': 1.66}\n",
      "{'loss': 2.6017, 'grad_norm': 3.6081676483154297, 'learning_rate': 2.2333333333333335e-05, 'epoch': 1.66}\n",
      "{'loss': 3.6538, 'grad_norm': 4.013033866882324, 'learning_rate': 2.22e-05, 'epoch': 1.67}\n",
      "{'loss': 3.3659, 'grad_norm': 4.0444536209106445, 'learning_rate': 2.206666666666667e-05, 'epoch': 1.68}\n",
      "{'loss': 3.0397, 'grad_norm': 4.289297103881836, 'learning_rate': 2.1933333333333332e-05, 'epoch': 1.69}\n",
      "{'loss': 2.8443, 'grad_norm': 4.115609645843506, 'learning_rate': 2.18e-05, 'epoch': 1.7}\n",
      "{'loss': 3.9307, 'grad_norm': 3.7922542095184326, 'learning_rate': 2.1666666666666667e-05, 'epoch': 1.7}\n",
      "{'loss': 3.5144, 'grad_norm': 5.275679111480713, 'learning_rate': 2.1533333333333333e-05, 'epoch': 1.71}\n",
      "{'loss': 3.6026, 'grad_norm': 6.118799209594727, 'learning_rate': 2.1400000000000002e-05, 'epoch': 1.72}\n",
      "{'loss': 2.7545, 'grad_norm': 2.7360477447509766, 'learning_rate': 2.1266666666666667e-05, 'epoch': 1.73}\n",
      "{'loss': 3.0541, 'grad_norm': 3.8181471824645996, 'learning_rate': 2.1133333333333337e-05, 'epoch': 1.74}\n",
      "{'loss': 3.9587, 'grad_norm': 4.092055320739746, 'learning_rate': 2.1e-05, 'epoch': 1.74}\n",
      "{'loss': 3.4841, 'grad_norm': 3.0659377574920654, 'learning_rate': 2.0866666666666668e-05, 'epoch': 1.75}\n",
      "{'loss': 4.4099, 'grad_norm': 4.373388767242432, 'learning_rate': 2.0733333333333334e-05, 'epoch': 1.76}\n",
      "{'loss': 3.3376, 'grad_norm': 4.516336917877197, 'learning_rate': 2.06e-05, 'epoch': 1.77}\n",
      "{'loss': 3.4185, 'grad_norm': 2.8513638973236084, 'learning_rate': 2.046666666666667e-05, 'epoch': 1.78}\n",
      "{'loss': 3.6094, 'grad_norm': 3.4683926105499268, 'learning_rate': 2.0333333333333334e-05, 'epoch': 1.78}\n",
      "{'loss': 3.3648, 'grad_norm': 3.2214748859405518, 'learning_rate': 2.0200000000000003e-05, 'epoch': 1.79}\n",
      "{'loss': 3.1632, 'grad_norm': 3.384833574295044, 'learning_rate': 2.0066666666666665e-05, 'epoch': 1.8}\n",
      "{'loss': 3.543, 'grad_norm': 5.297913551330566, 'learning_rate': 1.9933333333333334e-05, 'epoch': 1.81}\n",
      "{'loss': 3.0762, 'grad_norm': 4.891739845275879, 'learning_rate': 1.9800000000000004e-05, 'epoch': 1.82}\n",
      "{'loss': 3.4991, 'grad_norm': 2.836068868637085, 'learning_rate': 1.9666666666666666e-05, 'epoch': 1.82}\n",
      "{'loss': 3.4844, 'grad_norm': 3.4078924655914307, 'learning_rate': 1.9533333333333335e-05, 'epoch': 1.83}\n",
      "{'loss': 3.9775, 'grad_norm': 2.2844698429107666, 'learning_rate': 1.94e-05, 'epoch': 1.84}\n",
      "{'loss': 3.8193, 'grad_norm': 3.6420016288757324, 'learning_rate': 1.926666666666667e-05, 'epoch': 1.85}\n",
      "{'loss': 3.1821, 'grad_norm': 3.552475929260254, 'learning_rate': 1.9133333333333332e-05, 'epoch': 1.86}\n",
      "{'loss': 2.8319, 'grad_norm': 2.8900341987609863, 'learning_rate': 1.9e-05, 'epoch': 1.86}\n",
      "{'loss': 2.7482, 'grad_norm': 3.4319400787353516, 'learning_rate': 1.886666666666667e-05, 'epoch': 1.87}\n",
      "{'loss': 3.4153, 'grad_norm': 4.080052852630615, 'learning_rate': 1.8733333333333332e-05, 'epoch': 1.88}\n",
      "{'loss': 3.6518, 'grad_norm': 3.1049418449401855, 'learning_rate': 1.86e-05, 'epoch': 1.89}\n",
      "{'loss': 3.8846, 'grad_norm': 3.5862293243408203, 'learning_rate': 1.8466666666666667e-05, 'epoch': 1.9}\n",
      "{'loss': 3.6817, 'grad_norm': 3.135237216949463, 'learning_rate': 1.8333333333333333e-05, 'epoch': 1.9}\n",
      "{'loss': 2.9539, 'grad_norm': 4.113053798675537, 'learning_rate': 1.8200000000000002e-05, 'epoch': 1.91}\n",
      "{'loss': 3.6943, 'grad_norm': 3.3740546703338623, 'learning_rate': 1.8066666666666668e-05, 'epoch': 1.92}\n",
      "{'loss': 3.696, 'grad_norm': 4.223667144775391, 'learning_rate': 1.7933333333333337e-05, 'epoch': 1.93}\n",
      "{'loss': 3.6011, 'grad_norm': 3.4566490650177, 'learning_rate': 1.78e-05, 'epoch': 1.94}\n",
      "{'loss': 3.0088, 'grad_norm': 2.2398550510406494, 'learning_rate': 1.7666666666666668e-05, 'epoch': 1.94}\n",
      "{'loss': 3.2148, 'grad_norm': 3.4627292156219482, 'learning_rate': 1.7533333333333334e-05, 'epoch': 1.95}\n",
      "{'loss': 3.4084, 'grad_norm': 4.950009346008301, 'learning_rate': 1.74e-05, 'epoch': 1.96}\n",
      "{'loss': 3.1388, 'grad_norm': 4.103672981262207, 'learning_rate': 1.726666666666667e-05, 'epoch': 1.97}\n",
      "{'loss': 4.3596, 'grad_norm': 3.872211456298828, 'learning_rate': 1.7133333333333334e-05, 'epoch': 1.98}\n",
      "{'loss': 3.6137, 'grad_norm': 2.473783493041992, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.98}\n",
      "{'loss': 3.4124, 'grad_norm': 3.0270612239837646, 'learning_rate': 1.6866666666666666e-05, 'epoch': 1.99}\n",
      "{'loss': 2.5437, 'grad_norm': 4.5268473625183105, 'learning_rate': 1.6733333333333335e-05, 'epoch': 2.0}\n",
      " 67%|███████████████████████████▎             | 500/750 [00:43<00:15, 16.09it/s]/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 3.3248, 'grad_norm': 3.8994104862213135, 'learning_rate': 1.66e-05, 'epoch': 2.01}\n",
      "{'loss': 3.0881, 'grad_norm': 3.701300621032715, 'learning_rate': 1.6466666666666666e-05, 'epoch': 2.02}\n",
      "{'loss': 3.2972, 'grad_norm': 4.4006242752075195, 'learning_rate': 1.6333333333333335e-05, 'epoch': 2.02}\n",
      "{'loss': 3.4372, 'grad_norm': 4.01591682434082, 'learning_rate': 1.62e-05, 'epoch': 2.03}\n",
      "{'loss': 3.1716, 'grad_norm': 3.5632197856903076, 'learning_rate': 1.606666666666667e-05, 'epoch': 2.04}\n",
      "{'loss': 3.7688, 'grad_norm': 3.076669216156006, 'learning_rate': 1.5933333333333332e-05, 'epoch': 2.05}\n",
      "{'loss': 3.409, 'grad_norm': 5.038581848144531, 'learning_rate': 1.58e-05, 'epoch': 2.06}\n",
      "{'loss': 3.2763, 'grad_norm': 3.658384323120117, 'learning_rate': 1.5666666666666667e-05, 'epoch': 2.06}\n",
      "{'loss': 3.4571, 'grad_norm': 3.2021324634552, 'learning_rate': 1.5533333333333333e-05, 'epoch': 2.07}\n",
      "{'loss': 3.4376, 'grad_norm': 2.8316566944122314, 'learning_rate': 1.54e-05, 'epoch': 2.08}\n",
      "{'loss': 3.8196, 'grad_norm': 3.808934450149536, 'learning_rate': 1.5266666666666667e-05, 'epoch': 2.09}\n",
      "{'loss': 3.2893, 'grad_norm': 3.5306906700134277, 'learning_rate': 1.5133333333333333e-05, 'epoch': 2.1}\n",
      "{'loss': 3.2373, 'grad_norm': 2.7982733249664307, 'learning_rate': 1.5e-05, 'epoch': 2.1}\n",
      "{'loss': 3.301, 'grad_norm': 3.489295721054077, 'learning_rate': 1.4866666666666668e-05, 'epoch': 2.11}\n",
      "{'loss': 3.4565, 'grad_norm': 3.495845079421997, 'learning_rate': 1.4733333333333335e-05, 'epoch': 2.12}\n",
      "{'loss': 3.9819, 'grad_norm': 3.9825193881988525, 'learning_rate': 1.4599999999999999e-05, 'epoch': 2.13}\n",
      "{'loss': 2.8219, 'grad_norm': 3.2529149055480957, 'learning_rate': 1.4466666666666667e-05, 'epoch': 2.14}\n",
      "{'loss': 3.4742, 'grad_norm': 3.4582860469818115, 'learning_rate': 1.4333333333333334e-05, 'epoch': 2.14}\n",
      "{'loss': 3.5222, 'grad_norm': 3.403564929962158, 'learning_rate': 1.42e-05, 'epoch': 2.15}\n",
      "{'loss': 3.227, 'grad_norm': 5.207467079162598, 'learning_rate': 1.4066666666666667e-05, 'epoch': 2.16}\n",
      "{'loss': 2.3401, 'grad_norm': 3.6716225147247314, 'learning_rate': 1.3933333333333334e-05, 'epoch': 2.17}\n",
      "{'loss': 3.1955, 'grad_norm': 3.480910539627075, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.18}\n",
      "{'loss': 4.0257, 'grad_norm': 4.065297603607178, 'learning_rate': 1.3666666666666666e-05, 'epoch': 2.18}\n",
      "{'loss': 3.2224, 'grad_norm': 5.170894145965576, 'learning_rate': 1.3533333333333335e-05, 'epoch': 2.19}\n",
      "{'loss': 3.1535, 'grad_norm': 3.4468255043029785, 'learning_rate': 1.3400000000000002e-05, 'epoch': 2.2}\n",
      "{'loss': 3.3489, 'grad_norm': 4.8805365562438965, 'learning_rate': 1.3266666666666666e-05, 'epoch': 2.21}\n",
      "{'loss': 3.2287, 'grad_norm': 3.9760234355926514, 'learning_rate': 1.3133333333333334e-05, 'epoch': 2.22}\n",
      "{'loss': 3.5288, 'grad_norm': 2.521662950515747, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.22}\n",
      "{'loss': 4.0026, 'grad_norm': 2.350001335144043, 'learning_rate': 1.2866666666666668e-05, 'epoch': 2.23}\n",
      "{'loss': 3.1432, 'grad_norm': 3.20123291015625, 'learning_rate': 1.2733333333333334e-05, 'epoch': 2.24}\n",
      "{'loss': 2.4565, 'grad_norm': 3.9709396362304688, 'learning_rate': 1.2600000000000001e-05, 'epoch': 2.25}\n",
      "{'loss': 3.1614, 'grad_norm': 3.2082533836364746, 'learning_rate': 1.2466666666666667e-05, 'epoch': 2.26}\n",
      "{'loss': 2.8433, 'grad_norm': 4.217658996582031, 'learning_rate': 1.2333333333333334e-05, 'epoch': 2.26}\n",
      "{'loss': 3.8057, 'grad_norm': 3.122300863265991, 'learning_rate': 1.22e-05, 'epoch': 2.27}\n",
      "{'loss': 3.6032, 'grad_norm': 3.293837070465088, 'learning_rate': 1.2066666666666667e-05, 'epoch': 2.28}\n",
      "{'loss': 3.0171, 'grad_norm': 3.899473190307617, 'learning_rate': 1.1933333333333333e-05, 'epoch': 2.29}\n",
      "{'loss': 4.0198, 'grad_norm': 2.4805216789245605, 'learning_rate': 1.18e-05, 'epoch': 2.3}\n",
      "{'loss': 3.8814, 'grad_norm': 2.4292712211608887, 'learning_rate': 1.1666666666666668e-05, 'epoch': 2.3}\n",
      "{'loss': 3.442, 'grad_norm': 3.2105040550231934, 'learning_rate': 1.1533333333333334e-05, 'epoch': 2.31}\n",
      "{'loss': 2.941, 'grad_norm': 3.931124687194824, 'learning_rate': 1.1400000000000001e-05, 'epoch': 2.32}\n",
      "{'loss': 2.993, 'grad_norm': 3.7923460006713867, 'learning_rate': 1.1266666666666667e-05, 'epoch': 2.33}\n",
      "{'loss': 3.743, 'grad_norm': 3.1124720573425293, 'learning_rate': 1.1133333333333334e-05, 'epoch': 2.34}\n",
      "{'loss': 2.8435, 'grad_norm': 2.8587098121643066, 'learning_rate': 1.1000000000000001e-05, 'epoch': 2.34}\n",
      "{'loss': 3.1813, 'grad_norm': 2.8872227668762207, 'learning_rate': 1.0866666666666667e-05, 'epoch': 2.35}\n",
      "{'loss': 3.8801, 'grad_norm': 2.86955189704895, 'learning_rate': 1.0733333333333334e-05, 'epoch': 2.36}\n",
      "{'loss': 2.4516, 'grad_norm': 3.641140937805176, 'learning_rate': 1.06e-05, 'epoch': 2.37}\n",
      "{'loss': 3.4563, 'grad_norm': 3.5683233737945557, 'learning_rate': 1.0466666666666668e-05, 'epoch': 2.38}\n",
      "{'loss': 2.9344, 'grad_norm': 2.8118226528167725, 'learning_rate': 1.0333333333333333e-05, 'epoch': 2.38}\n",
      "{'loss': 3.3673, 'grad_norm': 3.324958324432373, 'learning_rate': 1.02e-05, 'epoch': 2.39}\n",
      "{'loss': 2.8706, 'grad_norm': 3.3724915981292725, 'learning_rate': 1.0066666666666668e-05, 'epoch': 2.4}\n",
      "{'loss': 2.7234, 'grad_norm': 3.3457512855529785, 'learning_rate': 9.933333333333334e-06, 'epoch': 2.41}\n",
      "{'loss': 3.5782, 'grad_norm': 3.6460583209991455, 'learning_rate': 9.800000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 2.2369, 'grad_norm': 3.7122554779052734, 'learning_rate': 9.666666666666667e-06, 'epoch': 2.42}\n",
      "{'loss': 3.1476, 'grad_norm': 2.9479973316192627, 'learning_rate': 9.533333333333334e-06, 'epoch': 2.43}\n",
      "{'loss': 2.7773, 'grad_norm': 2.9359517097473145, 'learning_rate': 9.4e-06, 'epoch': 2.44}\n",
      "{'loss': 3.5897, 'grad_norm': 2.872540235519409, 'learning_rate': 9.266666666666667e-06, 'epoch': 2.45}\n",
      "{'loss': 3.0598, 'grad_norm': 2.7823643684387207, 'learning_rate': 9.133333333333335e-06, 'epoch': 2.46}\n",
      "{'loss': 2.8995, 'grad_norm': 4.5003557205200195, 'learning_rate': 9e-06, 'epoch': 2.46}\n",
      "{'loss': 3.8429, 'grad_norm': 3.1775596141815186, 'learning_rate': 8.866666666666668e-06, 'epoch': 2.47}\n",
      "{'loss': 3.9193, 'grad_norm': 3.5215585231781006, 'learning_rate': 8.733333333333333e-06, 'epoch': 2.48}\n",
      "{'loss': 3.9821, 'grad_norm': 2.6528563499450684, 'learning_rate': 8.599999999999999e-06, 'epoch': 2.49}\n",
      "{'loss': 2.9963, 'grad_norm': 9.920449256896973, 'learning_rate': 8.466666666666666e-06, 'epoch': 2.5}\n",
      "{'loss': 4.1676, 'grad_norm': 3.4676051139831543, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n",
      "{'loss': 3.1294, 'grad_norm': 3.703139066696167, 'learning_rate': 8.200000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 3.5363, 'grad_norm': 2.8603851795196533, 'learning_rate': 8.066666666666667e-06, 'epoch': 2.52}\n",
      "{'loss': 2.917, 'grad_norm': 3.593130588531494, 'learning_rate': 7.933333333333334e-06, 'epoch': 2.53}\n",
      "{'loss': 3.5106, 'grad_norm': 3.609923839569092, 'learning_rate': 7.8e-06, 'epoch': 2.54}\n",
      "{'loss': 3.5413, 'grad_norm': 3.1036605834960938, 'learning_rate': 7.666666666666667e-06, 'epoch': 2.54}\n",
      "{'loss': 3.6003, 'grad_norm': 3.0204765796661377, 'learning_rate': 7.533333333333334e-06, 'epoch': 2.55}\n",
      "{'loss': 3.276, 'grad_norm': 2.5890920162200928, 'learning_rate': 7.4e-06, 'epoch': 2.56}\n",
      "{'loss': 3.8496, 'grad_norm': 3.4664907455444336, 'learning_rate': 7.266666666666668e-06, 'epoch': 2.57}\n",
      "{'loss': 2.8545, 'grad_norm': 3.713604688644409, 'learning_rate': 7.133333333333333e-06, 'epoch': 2.58}\n",
      "{'loss': 2.8428, 'grad_norm': 4.153688430786133, 'learning_rate': 7.000000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 3.7139, 'grad_norm': 2.905714511871338, 'learning_rate': 6.866666666666667e-06, 'epoch': 2.59}\n",
      "{'loss': 3.6756, 'grad_norm': 2.531562328338623, 'learning_rate': 6.733333333333333e-06, 'epoch': 2.6}\n",
      "{'loss': 3.263, 'grad_norm': 3.192798137664795, 'learning_rate': 6.6e-06, 'epoch': 2.61}\n",
      "{'loss': 3.227, 'grad_norm': 4.171813011169434, 'learning_rate': 6.466666666666667e-06, 'epoch': 2.62}\n",
      "{'loss': 3.4821, 'grad_norm': 3.5873332023620605, 'learning_rate': 6.333333333333334e-06, 'epoch': 2.62}\n",
      "{'loss': 2.9097, 'grad_norm': 3.7481393814086914, 'learning_rate': 6.2e-06, 'epoch': 2.63}\n",
      "{'loss': 3.6802, 'grad_norm': 2.7883384227752686, 'learning_rate': 6.066666666666667e-06, 'epoch': 2.64}\n",
      "{'loss': 3.5129, 'grad_norm': 4.027924537658691, 'learning_rate': 5.933333333333334e-06, 'epoch': 2.65}\n",
      "{'loss': 3.6192, 'grad_norm': 2.97638201713562, 'learning_rate': 5.8e-06, 'epoch': 2.66}\n",
      "{'loss': 2.6844, 'grad_norm': 2.9953694343566895, 'learning_rate': 5.666666666666667e-06, 'epoch': 2.66}\n",
      "{'loss': 3.0158, 'grad_norm': 3.6518759727478027, 'learning_rate': 5.5333333333333334e-06, 'epoch': 2.67}\n",
      "{'loss': 2.6235, 'grad_norm': 2.9553394317626953, 'learning_rate': 5.4e-06, 'epoch': 2.68}\n",
      "{'loss': 3.7601, 'grad_norm': 2.8464417457580566, 'learning_rate': 5.266666666666667e-06, 'epoch': 2.69}\n",
      "{'loss': 3.9305, 'grad_norm': 2.8174679279327393, 'learning_rate': 5.133333333333334e-06, 'epoch': 2.7}\n",
      "{'loss': 2.8853, 'grad_norm': 4.485396385192871, 'learning_rate': 5e-06, 'epoch': 2.7}\n",
      "{'loss': 3.0943, 'grad_norm': 4.312637805938721, 'learning_rate': 4.866666666666667e-06, 'epoch': 2.71}\n",
      "{'loss': 2.7286, 'grad_norm': 3.0653927326202393, 'learning_rate': 4.7333333333333335e-06, 'epoch': 2.72}\n",
      "{'loss': 2.8658, 'grad_norm': 3.714115858078003, 'learning_rate': 4.6e-06, 'epoch': 2.73}\n",
      "{'loss': 3.929, 'grad_norm': 2.5132741928100586, 'learning_rate': 4.4666666666666665e-06, 'epoch': 2.74}\n",
      "{'loss': 3.5749, 'grad_norm': 2.9703290462493896, 'learning_rate': 4.333333333333334e-06, 'epoch': 2.74}\n",
      "{'loss': 2.7909, 'grad_norm': 3.429757833480835, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.75}\n",
      "{'loss': 3.6065, 'grad_norm': 3.854504346847534, 'learning_rate': 4.066666666666666e-06, 'epoch': 2.76}\n",
      "{'loss': 4.2537, 'grad_norm': 2.9450297355651855, 'learning_rate': 3.9333333333333335e-06, 'epoch': 2.77}\n",
      "{'loss': 3.7093, 'grad_norm': 3.513416290283203, 'learning_rate': 3.8e-06, 'epoch': 2.78}\n",
      "{'loss': 3.1212, 'grad_norm': 3.226609230041504, 'learning_rate': 3.666666666666667e-06, 'epoch': 2.78}\n",
      "{'loss': 3.294, 'grad_norm': 4.215549945831299, 'learning_rate': 3.5333333333333335e-06, 'epoch': 2.79}\n",
      "{'loss': 3.0181, 'grad_norm': 3.4122111797332764, 'learning_rate': 3.4000000000000005e-06, 'epoch': 2.8}\n",
      "{'loss': 4.1753, 'grad_norm': 3.422041177749634, 'learning_rate': 3.2666666666666666e-06, 'epoch': 2.81}\n",
      "{'loss': 3.0472, 'grad_norm': 4.173520088195801, 'learning_rate': 3.133333333333333e-06, 'epoch': 2.82}\n",
      "{'loss': 3.7468, 'grad_norm': 3.138212203979492, 'learning_rate': 3e-06, 'epoch': 2.82}\n",
      "{'loss': 3.4449, 'grad_norm': 2.8776674270629883, 'learning_rate': 2.8666666666666666e-06, 'epoch': 2.83}\n",
      "{'loss': 3.2215, 'grad_norm': 2.6854071617126465, 'learning_rate': 2.7333333333333336e-06, 'epoch': 2.84}\n",
      "{'loss': 3.5251, 'grad_norm': 2.37727689743042, 'learning_rate': 2.6e-06, 'epoch': 2.85}\n",
      "{'loss': 3.3367, 'grad_norm': 2.4574170112609863, 'learning_rate': 2.4666666666666666e-06, 'epoch': 2.86}\n",
      "{'loss': 2.5762, 'grad_norm': 3.212461471557617, 'learning_rate': 2.3333333333333336e-06, 'epoch': 2.86}\n",
      "{'loss': 3.8291, 'grad_norm': 2.556856155395508, 'learning_rate': 2.2e-06, 'epoch': 2.87}\n",
      "{'loss': 3.2974, 'grad_norm': 3.6165590286254883, 'learning_rate': 2.0666666666666666e-06, 'epoch': 2.88}\n",
      "{'loss': 3.156, 'grad_norm': 3.4342105388641357, 'learning_rate': 1.9333333333333336e-06, 'epoch': 2.89}\n",
      "{'loss': 2.9393, 'grad_norm': 3.1947877407073975, 'learning_rate': 1.8e-06, 'epoch': 2.9}\n",
      "{'loss': 2.726, 'grad_norm': 4.3444037437438965, 'learning_rate': 1.6666666666666667e-06, 'epoch': 2.9}\n",
      "{'loss': 3.3213, 'grad_norm': 3.0247256755828857, 'learning_rate': 1.5333333333333334e-06, 'epoch': 2.91}\n",
      "{'loss': 3.6341, 'grad_norm': 2.829813003540039, 'learning_rate': 1.4000000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 3.6213, 'grad_norm': 6.172760486602783, 'learning_rate': 1.2666666666666667e-06, 'epoch': 2.93}\n",
      "{'loss': 2.9454, 'grad_norm': 3.1040937900543213, 'learning_rate': 1.1333333333333334e-06, 'epoch': 2.94}\n",
      "{'loss': 3.4941, 'grad_norm': 6.872143745422363, 'learning_rate': 1.0000000000000002e-06, 'epoch': 2.94}\n",
      "{'loss': 2.8383, 'grad_norm': 3.6191298961639404, 'learning_rate': 8.666666666666667e-07, 'epoch': 2.95}\n",
      "{'loss': 3.7474, 'grad_norm': 3.447955846786499, 'learning_rate': 7.333333333333333e-07, 'epoch': 2.96}\n",
      "{'loss': 2.4476, 'grad_norm': 3.564987897872925, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.97}\n",
      "{'loss': 2.9947, 'grad_norm': 5.268564701080322, 'learning_rate': 4.666666666666667e-07, 'epoch': 2.98}\n",
      "{'loss': 3.4184, 'grad_norm': 3.265712022781372, 'learning_rate': 3.3333333333333335e-07, 'epoch': 2.98}\n",
      "{'loss': 2.8938, 'grad_norm': 4.425856113433838, 'learning_rate': 2.0000000000000002e-07, 'epoch': 2.99}\n",
      "{'loss': 3.4503, 'grad_norm': 2.4523091316223145, 'learning_rate': 6.666666666666667e-08, 'epoch': 3.0}\n",
      "{'train_runtime': 62.4184, 'train_samples_per_second': 24.031, 'train_steps_per_second': 12.016, 'train_loss': 3.9627256488800047, 'epoch': 3.0}\n",
      "100%|█████████████████████████████████████████| 750/750 [01:02<00:00, 12.02it/s]\n",
      "   ✓ Training complete!\n",
      "\n",
      "6. Saving adapters...\n",
      "   ✓ Saved to ./finance_lora_adapters\n",
      "\n",
      "7. Testing fine-tuned model...\n",
      "\n",
      "   Q: What is a stock?\n",
      "   A: The company is valued at $1.2 billion in the first quarter of this year, up from the same period a year ago, according to a report released on Tuesday. The company is the second-largest producer of electronic products in\n",
      "\n",
      "   Q: How do bonds work?\n",
      "   A: The bond market is growing at an annual rate of 2.5% in the first quarter of this year, according to data released by the European Central Bank (ECB) on Monday. The euro zone’s second-largest\n",
      "\n",
      "   Q: Explain portfolio diversification in one sentence.\n",
      "   A: In the last two years, net assets have increased by 2.5% compared with the same period a year ago. Source: Financial Times The growth in net assets in the two-year period is expected to increase by 1.\n",
      "\n",
      "   Q: What is the risk of long-term government bonds?\n",
      "   A: In the first quarter of 2015, the value of the bonds rose to $1.8 billion, up from a year earlier. This year, the price of bonds fell to $2.6 billion, down from the previous year.\n",
      "\n",
      "   Q: Why do companies pay dividends?\n",
      "   A: The value of the shares in the company rose to a record high of $1.2 billion in the first quarter of this year, up from a year ago, according to a new report. According to the report, the company has\n",
      "\n",
      "   Q: How does inflation affect bond prices?\n",
      "   A: In the first half of the year, the value of the euro rose to a record high of $1.6 billion, up from a year ago. The euro also rose to an all-time low of $2.5 billion,\n"
     ]
    }
   ],
   "source": [
    "!python finance_lora.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5972b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  MCP SERVER: Finance Tools\n",
      "======================================================================\n",
      "\n",
      "Available Tools:\n",
      "  1. get_stock_price(symbol) - Real stock prices\n",
      "  2. scrape_finance_news(topic) - Finance news scraping\n",
      "  3. calculate_investment(initial, rate, years) - Investment math\n",
      "\n",
      "Starting MCP server...\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python finance_mcp_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252ff55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
