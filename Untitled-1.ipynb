{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9628f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.13/site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: yfinance in /opt/anaconda3/lib/python3.13/site-packages (0.2.66)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.13/site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.13/site-packages (1.13.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (4.57.3)\n",
      "Requirement already satisfied: peft in /opt/anaconda3/lib/python3.13/site-packages (0.18.0)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.13/site-packages (4.4.1)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: mcp in /opt/anaconda3/lib/python3.13/site-packages (1.23.1)\n",
      "Requirement already satisfied: google-generativeai in /opt/anaconda3/lib/python3.13/site-packages (0.8.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.13/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2.1.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (4.3.7)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (3.18.3)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (5.29.3)\n",
      "Requirement already satisfied: websockets>=13.0 in /opt/anaconda3/lib/python3.13/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.13/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/anaconda3/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.11.10)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (4.23.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (2.6.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (2.12.5)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /opt/anaconda3/lib/python3.13/site-packages (from pyjwt[crypto]>=2.10.1->mcp) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (3.0.3)\n",
      "Requirement already satisfied: starlette>=0.27 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.50.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /opt/anaconda3/lib/python3.13/site-packages (from mcp) (0.38.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.11.0->mcp) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.11.0->mcp) (2.41.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/lib/python3.13/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.18.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.13/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic-settings>=2.5.2->mcp) (1.1.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from pyjwt[crypto]>=2.10.1->mcp) (44.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.13/site-packages (from uvicorn>=0.31.1->mcp) (8.1.8)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /opt/anaconda3/lib/python3.13/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests yfinance sentence-transformers faiss-cpu transformers peft datasets torch mcp google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf3f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are Ready\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import faiss; import yfinance; print('We are Ready')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0c8ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SCRAPING FINANCE WIKIPEDIA ARTICLES\n",
      "======================================================================\n",
      "\n",
      "✓ Scraping: Stock\n",
      "  ✓ Success! 3865 chars\n",
      "\n",
      "✓ Scraping: Bond (finance)\n",
      "  ✓ Success! 4179 chars\n",
      "\n",
      "✓ Scraping: Government bond\n",
      "  ✓ Success! 3308 chars\n",
      "\n",
      "✓ Scraping: Corporate bond\n",
      "  ✓ Success! 3322 chars\n",
      "\n",
      "✓ Scraping: Fixed income\n",
      "  ✓ Success! 5364 chars\n",
      "\n",
      "✓ Scraping: Dividend\n",
      "  ✓ Success! 3861 chars\n",
      "\n",
      "✓ Scraping: Portfolio\n",
      "  ✓ Success! 23 chars\n",
      "\n",
      "✓ Scraping: Investment\n",
      "  ✓ Success! 1752 chars\n",
      "\n",
      "✓ Scraping: Risk management\n",
      "  ✓ Success! 4784 chars\n",
      "======================================================================\n",
      "SCRAPING FINANCE NEWS/INFO SITES\n",
      "======================================================================\n",
      "\n",
      "✓ Scraping: https://www.google.com/finance/markets\n",
      "  ✓ Success! 0 chars\n",
      "\n",
      "✓ Scraping: https://finance.yahoo.com/\n",
      "  ✓ Success! 788 chars\n",
      "\n",
      "✓ Scraping: https://www.investopedia.com/markets-news-4427782\n",
      "  ✓ Success! 0 chars\n",
      "\n",
      "✓ Scraping: https://www.marketwatch.com/\n",
      "  ✗ Error: status 401\n",
      "\n",
      "✓ Saved 12 documents to finance_knowledge_base.json\n"
     ]
    }
   ],
   "source": [
    "!python finance_wiki_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09213e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING HUGGING FACE FINANCE DATASET\n",
      "======================================================================\n",
      "Dataset : financial_phrasebank\n",
      "Subset  : sentences_allagree\n",
      "Split   : train\n",
      "Limit   : 500\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "✓ Loaded 500 documents from Hugging Face zip\n",
      "\n",
      "✓ Saved 500 documents to finance_knowledge_base.json\n"
     ]
    }
   ],
   "source": [
    "!python finance_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c29e6c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TASK 1: RAG PIPELINE WITH FINANCE DATA\n",
      "======================================================================\n",
      "\n",
      "1. Loading finance knowledge base...\n",
      "   ✓ Loaded 500 documents\n",
      "\n",
      "2. Creating embeddings...\n",
      "   ✓ Created 500 embeddings\n",
      "\n",
      "3. Building FAISS index...\n",
      "   ✓ Index ready with 500 documents\n",
      "\n",
      "4. Loading text generator...\n",
      "Device set to use mps:0\n",
      "   ✓ Text generator ready\n",
      "\n",
      "5. Testing RAG with finance questions...\n",
      "\n",
      "   Q: What is a stock?\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "   A: Based on this finance info:\n",
      "- SHARE REPURCHASE 11.01.2008 In the Helsinki Stock Exchange On behalf of Sampo plc Danske Bank A-S Helsinki Branch...\n",
      "- S\n",
      "\n",
      "   Q: What are bonds?\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "   A: Based on this finance info:\n",
      "- Finnish Talvivaara Mining Co HEL : TLV1V said Thursday it had picked BofA Merrill Lynch and JPMorgan NYSE : JPM as joint\n",
      "\n",
      "   Q: What is dividend investing?\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "   A: Based on this finance info:\n",
      "- Its board of directors will propose a dividend of EUR0 .12 per share for 2010 , up from the EUR0 .08 per share paid in 2\n"
     ]
    }
   ],
   "source": [
    "!python finance_rag.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "414d770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Preparing finance training data...\n",
      "   ✓ Created 500 QA-style training examples (from knowledge base if available)\n",
      "\n",
      "2. Tokenizing data...\n",
      "Map: 100%|██████████████████████████| 500/500 [00:00<00:00, 20794.35 examples/s]\n",
      "   ✓ Tokenized\n",
      "\n",
      "3. Loading base model...\n",
      "   ✓ Loaded distilgpt2\n",
      "\n",
      "4. Configuring LoRA...\n",
      "/opt/anaconda3/lib/python3.13/site-packages/peft/tuners/lora/layer.py:2285: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "   ✓ LoRA configured\n",
      "   ✓ Trainable: 147,456 / 82,060,032 (0.18%)\n",
      "\n",
      "5. Training (this takes ~2 minutes)...\n",
      "  0%|                                                   | 0/750 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "{'loss': 6.0598, 'grad_norm': 0.9370530247688293, 'learning_rate': 4.993333333333334e-05, 'epoch': 0.01}\n",
      "{'loss': 5.2261, 'grad_norm': 0.8249183297157288, 'learning_rate': 4.9800000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 5.8016, 'grad_norm': 1.0470705032348633, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.02}\n",
      "{'loss': 5.9098, 'grad_norm': 0.9489023685455322, 'learning_rate': 4.9533333333333336e-05, 'epoch': 0.03}\n",
      "{'loss': 5.573, 'grad_norm': 0.7045973539352417, 'learning_rate': 4.94e-05, 'epoch': 0.04}\n",
      "{'loss': 6.3409, 'grad_norm': 1.2135287523269653, 'learning_rate': 4.926666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 5.447, 'grad_norm': 1.1530791521072388, 'learning_rate': 4.913333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 5.9289, 'grad_norm': 1.3060754537582397, 'learning_rate': 4.9e-05, 'epoch': 0.06}\n",
      "{'loss': 5.7098, 'grad_norm': 0.9332523941993713, 'learning_rate': 4.886666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 5.8469, 'grad_norm': 1.1073613166809082, 'learning_rate': 4.8733333333333337e-05, 'epoch': 0.08}\n",
      "{'loss': 5.7247, 'grad_norm': 1.2876428365707397, 'learning_rate': 4.86e-05, 'epoch': 0.09}\n",
      "{'loss': 5.5687, 'grad_norm': 1.0593206882476807, 'learning_rate': 4.8466666666666675e-05, 'epoch': 0.1}\n",
      "{'loss': 5.4531, 'grad_norm': 1.2641633749008179, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.1}\n",
      "{'loss': 6.1349, 'grad_norm': 1.4184612035751343, 'learning_rate': 4.82e-05, 'epoch': 0.11}\n",
      "{'loss': 5.5605, 'grad_norm': 1.3962347507476807, 'learning_rate': 4.806666666666667e-05, 'epoch': 0.12}\n",
      "{'loss': 5.7311, 'grad_norm': 1.4223843812942505, 'learning_rate': 4.793333333333334e-05, 'epoch': 0.13}\n",
      "{'loss': 5.1058, 'grad_norm': 1.0759155750274658, 'learning_rate': 4.78e-05, 'epoch': 0.14}\n",
      "{'loss': 5.6931, 'grad_norm': 1.2979527711868286, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.14}\n",
      "{'loss': 5.8735, 'grad_norm': 1.250248670578003, 'learning_rate': 4.7533333333333334e-05, 'epoch': 0.15}\n",
      "{'loss': 6.1772, 'grad_norm': 1.524712324142456, 'learning_rate': 4.74e-05, 'epoch': 0.16}\n",
      "{'loss': 4.9312, 'grad_norm': 1.4315390586853027, 'learning_rate': 4.726666666666667e-05, 'epoch': 0.17}\n",
      "{'loss': 5.9613, 'grad_norm': 1.8474100828170776, 'learning_rate': 4.713333333333333e-05, 'epoch': 0.18}\n",
      "{'loss': 5.3151, 'grad_norm': 1.3149994611740112, 'learning_rate': 4.7e-05, 'epoch': 0.18}\n",
      "{'loss': 5.8733, 'grad_norm': 1.9808192253112793, 'learning_rate': 4.686666666666667e-05, 'epoch': 0.19}\n",
      "{'loss': 5.4488, 'grad_norm': 1.2751479148864746, 'learning_rate': 4.6733333333333335e-05, 'epoch': 0.2}\n",
      "{'loss': 5.6907, 'grad_norm': 1.4415184259414673, 'learning_rate': 4.660000000000001e-05, 'epoch': 0.21}\n",
      "{'loss': 5.7048, 'grad_norm': 1.9202371835708618, 'learning_rate': 4.646666666666667e-05, 'epoch': 0.22}\n",
      "{'loss': 5.9819, 'grad_norm': 2.236426591873169, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.22}\n",
      "{'loss': 5.3878, 'grad_norm': 1.460336685180664, 'learning_rate': 4.6200000000000005e-05, 'epoch': 0.23}\n",
      "{'loss': 5.7641, 'grad_norm': 1.4870855808258057, 'learning_rate': 4.606666666666667e-05, 'epoch': 0.24}\n",
      "{'loss': 5.2191, 'grad_norm': 1.5781030654907227, 'learning_rate': 4.5933333333333336e-05, 'epoch': 0.25}\n",
      "{'loss': 5.2982, 'grad_norm': 1.9235492944717407, 'learning_rate': 4.58e-05, 'epoch': 0.26}\n",
      "{'loss': 5.1151, 'grad_norm': 1.6124274730682373, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.26}\n",
      "{'loss': 5.4449, 'grad_norm': 1.8566936254501343, 'learning_rate': 4.553333333333333e-05, 'epoch': 0.27}\n",
      "{'loss': 4.983, 'grad_norm': 1.4060258865356445, 'learning_rate': 4.5400000000000006e-05, 'epoch': 0.28}\n",
      "{'loss': 5.2653, 'grad_norm': 1.7335257530212402, 'learning_rate': 4.526666666666667e-05, 'epoch': 0.29}\n",
      "{'loss': 5.3583, 'grad_norm': 1.505043625831604, 'learning_rate': 4.513333333333333e-05, 'epoch': 0.3}\n",
      "{'loss': 5.9214, 'grad_norm': 2.024843692779541, 'learning_rate': 4.5e-05, 'epoch': 0.3}\n",
      "{'loss': 5.016, 'grad_norm': 2.0536134243011475, 'learning_rate': 4.486666666666667e-05, 'epoch': 0.31}\n",
      "{'loss': 5.1307, 'grad_norm': 1.642247200012207, 'learning_rate': 4.473333333333334e-05, 'epoch': 0.32}\n",
      "{'loss': 5.7207, 'grad_norm': 1.9349544048309326, 'learning_rate': 4.46e-05, 'epoch': 0.33}\n",
      "{'loss': 5.583, 'grad_norm': 1.6714309453964233, 'learning_rate': 4.4466666666666666e-05, 'epoch': 0.34}\n",
      "{'loss': 5.527, 'grad_norm': 1.4167925119400024, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.34}\n",
      "{'loss': 5.0676, 'grad_norm': 1.7120493650436401, 'learning_rate': 4.4200000000000004e-05, 'epoch': 0.35}\n",
      "{'loss': 5.0944, 'grad_norm': 2.033512830734253, 'learning_rate': 4.406666666666667e-05, 'epoch': 0.36}\n",
      "{'loss': 4.9461, 'grad_norm': 1.54387366771698, 'learning_rate': 4.3933333333333335e-05, 'epoch': 0.37}\n",
      "{'loss': 5.0306, 'grad_norm': 1.5645948648452759, 'learning_rate': 4.38e-05, 'epoch': 0.38}\n",
      "{'loss': 4.9764, 'grad_norm': 1.9365707635879517, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.38}\n",
      "{'loss': 5.0066, 'grad_norm': 2.0602102279663086, 'learning_rate': 4.353333333333334e-05, 'epoch': 0.39}\n",
      "{'loss': 5.0081, 'grad_norm': 1.8028980493545532, 'learning_rate': 4.3400000000000005e-05, 'epoch': 0.4}\n",
      "{'loss': 5.4556, 'grad_norm': 2.5364365577697754, 'learning_rate': 4.3266666666666664e-05, 'epoch': 0.41}\n",
      "{'loss': 4.836, 'grad_norm': 2.280677080154419, 'learning_rate': 4.3133333333333336e-05, 'epoch': 0.42}\n",
      "{'loss': 5.3952, 'grad_norm': 1.9147658348083496, 'learning_rate': 4.3e-05, 'epoch': 0.42}\n",
      "{'loss': 5.4094, 'grad_norm': 2.2808852195739746, 'learning_rate': 4.286666666666667e-05, 'epoch': 0.43}\n",
      "{'loss': 5.2553, 'grad_norm': 2.0294511318206787, 'learning_rate': 4.273333333333333e-05, 'epoch': 0.44}\n",
      "{'loss': 5.1277, 'grad_norm': 2.0359768867492676, 'learning_rate': 4.26e-05, 'epoch': 0.45}\n",
      "{'loss': 4.6513, 'grad_norm': 1.6853681802749634, 'learning_rate': 4.246666666666667e-05, 'epoch': 0.46}\n",
      "{'loss': 4.5845, 'grad_norm': 1.5567939281463623, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.46}\n",
      "{'loss': 4.8744, 'grad_norm': 1.9926685094833374, 'learning_rate': 4.22e-05, 'epoch': 0.47}\n",
      "{'loss': 4.9731, 'grad_norm': 1.8966797590255737, 'learning_rate': 4.206666666666667e-05, 'epoch': 0.48}\n",
      "{'loss': 5.4816, 'grad_norm': 2.135746717453003, 'learning_rate': 4.1933333333333334e-05, 'epoch': 0.49}\n",
      "{'loss': 4.8334, 'grad_norm': 1.8081845045089722, 'learning_rate': 4.18e-05, 'epoch': 0.5}\n",
      "{'loss': 4.4128, 'grad_norm': 1.7142270803451538, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n",
      "{'loss': 5.3899, 'grad_norm': 1.6478068828582764, 'learning_rate': 4.153333333333334e-05, 'epoch': 0.51}\n",
      "{'loss': 5.133, 'grad_norm': 2.6728670597076416, 'learning_rate': 4.14e-05, 'epoch': 0.52}\n",
      "{'loss': 5.0576, 'grad_norm': 2.4149510860443115, 'learning_rate': 4.126666666666667e-05, 'epoch': 0.53}\n",
      "{'loss': 5.2552, 'grad_norm': 2.3545711040496826, 'learning_rate': 4.1133333333333335e-05, 'epoch': 0.54}\n",
      "{'loss': 4.7361, 'grad_norm': 2.3881139755249023, 'learning_rate': 4.1e-05, 'epoch': 0.54}\n",
      "{'loss': 5.1742, 'grad_norm': 2.1198153495788574, 'learning_rate': 4.086666666666667e-05, 'epoch': 0.55}\n",
      "{'loss': 4.6139, 'grad_norm': 2.4956445693969727, 'learning_rate': 4.073333333333333e-05, 'epoch': 0.56}\n",
      "{'loss': 4.325, 'grad_norm': 2.575796365737915, 'learning_rate': 4.0600000000000004e-05, 'epoch': 0.57}\n",
      "{'loss': 4.4435, 'grad_norm': 2.0328705310821533, 'learning_rate': 4.046666666666667e-05, 'epoch': 0.58}\n",
      "{'loss': 4.8827, 'grad_norm': 1.767015814781189, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.58}\n",
      "{'loss': 4.8503, 'grad_norm': 3.0704729557037354, 'learning_rate': 4.02e-05, 'epoch': 0.59}\n",
      "{'loss': 4.3663, 'grad_norm': 2.4889721870422363, 'learning_rate': 4.006666666666667e-05, 'epoch': 0.6}\n",
      "{'loss': 5.2378, 'grad_norm': 2.5424561500549316, 'learning_rate': 3.993333333333333e-05, 'epoch': 0.61}\n",
      "{'loss': 4.5834, 'grad_norm': 2.3262453079223633, 'learning_rate': 3.9800000000000005e-05, 'epoch': 0.62}\n",
      "{'loss': 4.8043, 'grad_norm': 2.2306034564971924, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.62}\n",
      "{'loss': 4.6093, 'grad_norm': 1.9842427968978882, 'learning_rate': 3.9533333333333337e-05, 'epoch': 0.63}\n",
      "{'loss': 4.7854, 'grad_norm': 2.1830685138702393, 'learning_rate': 3.94e-05, 'epoch': 0.64}\n",
      "{'loss': 4.7083, 'grad_norm': 2.239199638366699, 'learning_rate': 3.926666666666667e-05, 'epoch': 0.65}\n",
      "{'loss': 4.6717, 'grad_norm': 3.6242425441741943, 'learning_rate': 3.9133333333333334e-05, 'epoch': 0.66}\n",
      "{'loss': 4.6283, 'grad_norm': 2.907578229904175, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.66}\n",
      "{'loss': 4.8557, 'grad_norm': 2.726161241531372, 'learning_rate': 3.8866666666666665e-05, 'epoch': 0.67}\n",
      "{'loss': 4.6386, 'grad_norm': 2.7446346282958984, 'learning_rate': 3.873333333333333e-05, 'epoch': 0.68}\n",
      "{'loss': 5.1472, 'grad_norm': 2.0925605297088623, 'learning_rate': 3.86e-05, 'epoch': 0.69}\n",
      "{'loss': 4.3895, 'grad_norm': 2.7511510848999023, 'learning_rate': 3.846666666666667e-05, 'epoch': 0.7}\n",
      "{'loss': 4.6607, 'grad_norm': 2.5533735752105713, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.7}\n",
      "{'loss': 4.2153, 'grad_norm': 2.2194325923919678, 'learning_rate': 3.82e-05, 'epoch': 0.71}\n",
      "{'loss': 4.858, 'grad_norm': 2.331831216812134, 'learning_rate': 3.8066666666666666e-05, 'epoch': 0.72}\n",
      "{'loss': 4.5972, 'grad_norm': 2.4068830013275146, 'learning_rate': 3.793333333333334e-05, 'epoch': 0.73}\n",
      "{'loss': 4.055, 'grad_norm': 2.5335164070129395, 'learning_rate': 3.7800000000000004e-05, 'epoch': 0.74}\n",
      "{'loss': 4.3191, 'grad_norm': 2.193470001220703, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.74}\n",
      "{'loss': 4.1205, 'grad_norm': 2.8854007720947266, 'learning_rate': 3.7533333333333335e-05, 'epoch': 0.75}\n",
      "{'loss': 4.7842, 'grad_norm': 2.9022552967071533, 'learning_rate': 3.74e-05, 'epoch': 0.76}\n",
      "{'loss': 4.5612, 'grad_norm': 1.792222261428833, 'learning_rate': 3.726666666666667e-05, 'epoch': 0.77}\n",
      "{'loss': 4.6185, 'grad_norm': 2.846597194671631, 'learning_rate': 3.713333333333334e-05, 'epoch': 0.78}\n",
      "{'loss': 4.3582, 'grad_norm': 4.000738620758057, 'learning_rate': 3.7e-05, 'epoch': 0.78}\n",
      "{'loss': 4.2514, 'grad_norm': 2.2682723999023438, 'learning_rate': 3.6866666666666664e-05, 'epoch': 0.79}\n",
      "{'loss': 3.7439, 'grad_norm': 2.681356191635132, 'learning_rate': 3.6733333333333336e-05, 'epoch': 0.8}\n",
      "{'loss': 4.4133, 'grad_norm': 2.891940116882324, 'learning_rate': 3.66e-05, 'epoch': 0.81}\n",
      "{'loss': 4.3741, 'grad_norm': 1.7010083198547363, 'learning_rate': 3.646666666666667e-05, 'epoch': 0.82}\n",
      "{'loss': 4.3692, 'grad_norm': 2.1829938888549805, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.82}\n",
      "{'loss': 4.3373, 'grad_norm': 2.492750644683838, 'learning_rate': 3.62e-05, 'epoch': 0.83}\n",
      "{'loss': 4.1484, 'grad_norm': 3.0783169269561768, 'learning_rate': 3.606666666666667e-05, 'epoch': 0.84}\n",
      "{'loss': 4.4375, 'grad_norm': 2.6361539363861084, 'learning_rate': 3.593333333333334e-05, 'epoch': 0.85}\n",
      "{'loss': 4.586, 'grad_norm': 2.8453547954559326, 'learning_rate': 3.58e-05, 'epoch': 0.86}\n",
      "{'loss': 4.2793, 'grad_norm': 2.6696572303771973, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.86}\n",
      "{'loss': 4.6534, 'grad_norm': 3.547374725341797, 'learning_rate': 3.5533333333333334e-05, 'epoch': 0.87}\n",
      "{'loss': 4.3273, 'grad_norm': 4.217532634735107, 'learning_rate': 3.54e-05, 'epoch': 0.88}\n",
      "{'loss': 3.7231, 'grad_norm': 3.8432276248931885, 'learning_rate': 3.526666666666667e-05, 'epoch': 0.89}\n",
      "{'loss': 3.8348, 'grad_norm': 2.9583141803741455, 'learning_rate': 3.513333333333334e-05, 'epoch': 0.9}\n",
      "{'loss': 3.9722, 'grad_norm': 2.488992929458618, 'learning_rate': 3.5e-05, 'epoch': 0.9}\n",
      "{'loss': 4.0694, 'grad_norm': 2.8935811519622803, 'learning_rate': 3.486666666666667e-05, 'epoch': 0.91}\n",
      "{'loss': 3.8965, 'grad_norm': 3.5662856101989746, 'learning_rate': 3.4733333333333335e-05, 'epoch': 0.92}\n",
      "{'loss': 4.1088, 'grad_norm': 3.7379138469696045, 'learning_rate': 3.46e-05, 'epoch': 0.93}\n",
      "{'loss': 4.1689, 'grad_norm': 3.1919310092926025, 'learning_rate': 3.4466666666666666e-05, 'epoch': 0.94}\n",
      "{'loss': 4.011, 'grad_norm': 3.1783130168914795, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.94}\n",
      "{'loss': 3.5986, 'grad_norm': 5.977421283721924, 'learning_rate': 3.4200000000000005e-05, 'epoch': 0.95}\n",
      "{'loss': 4.372, 'grad_norm': 3.4849026203155518, 'learning_rate': 3.406666666666667e-05, 'epoch': 0.96}\n",
      "{'loss': 4.1047, 'grad_norm': 3.1741061210632324, 'learning_rate': 3.3933333333333336e-05, 'epoch': 0.97}\n",
      "{'loss': 4.1409, 'grad_norm': 2.689913511276245, 'learning_rate': 3.38e-05, 'epoch': 0.98}\n",
      "{'loss': 3.7705, 'grad_norm': 3.6506638526916504, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.98}\n",
      "{'loss': 3.5913, 'grad_norm': 3.6649248600006104, 'learning_rate': 3.353333333333333e-05, 'epoch': 0.99}\n",
      "{'loss': 4.0874, 'grad_norm': 3.004210948944092, 'learning_rate': 3.3400000000000005e-05, 'epoch': 1.0}\n",
      " 33%|█████████████▋                           | 250/750 [00:21<00:40, 12.41it/s]/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 3.2081, 'grad_norm': 4.1279988288879395, 'learning_rate': 3.326666666666667e-05, 'epoch': 1.01}\n",
      "{'loss': 3.6853, 'grad_norm': 4.1245927810668945, 'learning_rate': 3.313333333333333e-05, 'epoch': 1.02}\n",
      "{'loss': 4.1573, 'grad_norm': 3.057270050048828, 'learning_rate': 3.3e-05, 'epoch': 1.02}\n",
      "{'loss': 3.6944, 'grad_norm': 3.7549290657043457, 'learning_rate': 3.286666666666667e-05, 'epoch': 1.03}\n",
      "{'loss': 3.7702, 'grad_norm': 3.020686149597168, 'learning_rate': 3.2733333333333334e-05, 'epoch': 1.04}\n",
      "{'loss': 4.3756, 'grad_norm': 3.6742234230041504, 'learning_rate': 3.26e-05, 'epoch': 1.05}\n",
      "{'loss': 4.0868, 'grad_norm': 2.963663339614868, 'learning_rate': 3.2466666666666665e-05, 'epoch': 1.06}\n",
      "{'loss': 4.1874, 'grad_norm': 3.1690399646759033, 'learning_rate': 3.233333333333333e-05, 'epoch': 1.06}\n",
      "{'loss': 3.9432, 'grad_norm': 4.761812210083008, 'learning_rate': 3.2200000000000003e-05, 'epoch': 1.07}\n",
      "{'loss': 3.9988, 'grad_norm': 3.1220390796661377, 'learning_rate': 3.206666666666667e-05, 'epoch': 1.08}\n",
      "{'loss': 4.2785, 'grad_norm': 3.0620081424713135, 'learning_rate': 3.1933333333333335e-05, 'epoch': 1.09}\n",
      "{'loss': 4.0093, 'grad_norm': 3.636152982711792, 'learning_rate': 3.18e-05, 'epoch': 1.1}\n",
      "{'loss': 3.4308, 'grad_norm': 3.8315629959106445, 'learning_rate': 3.1666666666666666e-05, 'epoch': 1.1}\n",
      "{'loss': 3.2755, 'grad_norm': 3.2687532901763916, 'learning_rate': 3.153333333333334e-05, 'epoch': 1.11}\n",
      "{'loss': 3.5679, 'grad_norm': 5.535118103027344, 'learning_rate': 3.1400000000000004e-05, 'epoch': 1.12}\n",
      "{'loss': 3.5434, 'grad_norm': 4.581258773803711, 'learning_rate': 3.126666666666666e-05, 'epoch': 1.13}\n",
      "{'loss': 4.0761, 'grad_norm': 4.733734607696533, 'learning_rate': 3.1133333333333336e-05, 'epoch': 1.14}\n",
      "{'loss': 3.7801, 'grad_norm': 4.20756721496582, 'learning_rate': 3.1e-05, 'epoch': 1.14}\n",
      "{'loss': 3.7029, 'grad_norm': 3.858231544494629, 'learning_rate': 3.086666666666667e-05, 'epoch': 1.15}\n",
      "{'loss': 4.1537, 'grad_norm': 4.100427150726318, 'learning_rate': 3.073333333333334e-05, 'epoch': 1.16}\n",
      "{'loss': 3.5868, 'grad_norm': 3.358124017715454, 'learning_rate': 3.06e-05, 'epoch': 1.17}\n",
      "{'loss': 3.6434, 'grad_norm': 3.4392075538635254, 'learning_rate': 3.0466666666666664e-05, 'epoch': 1.18}\n",
      "{'loss': 3.0942, 'grad_norm': 4.834225654602051, 'learning_rate': 3.0333333333333337e-05, 'epoch': 1.18}\n",
      "{'loss': 3.955, 'grad_norm': 4.078135967254639, 'learning_rate': 3.02e-05, 'epoch': 1.19}\n",
      "{'loss': 3.1849, 'grad_norm': 3.4756927490234375, 'learning_rate': 3.006666666666667e-05, 'epoch': 1.2}\n",
      "{'loss': 3.588, 'grad_norm': 3.1022703647613525, 'learning_rate': 2.9933333333333337e-05, 'epoch': 1.21}\n",
      "{'loss': 3.9866, 'grad_norm': 4.093574047088623, 'learning_rate': 2.98e-05, 'epoch': 1.22}\n",
      "{'loss': 3.2735, 'grad_norm': 5.430191516876221, 'learning_rate': 2.9666666666666672e-05, 'epoch': 1.22}\n",
      "{'loss': 2.9482, 'grad_norm': 4.292843341827393, 'learning_rate': 2.9533333333333334e-05, 'epoch': 1.23}\n",
      "{'loss': 4.0445, 'grad_norm': 3.1207046508789062, 'learning_rate': 2.94e-05, 'epoch': 1.24}\n",
      "{'loss': 3.8932, 'grad_norm': 4.000523567199707, 'learning_rate': 2.926666666666667e-05, 'epoch': 1.25}\n",
      "{'loss': 4.1188, 'grad_norm': 3.1572017669677734, 'learning_rate': 2.9133333333333334e-05, 'epoch': 1.26}\n",
      "{'loss': 3.8097, 'grad_norm': 3.772244691848755, 'learning_rate': 2.9e-05, 'epoch': 1.26}\n",
      "{'loss': 3.5704, 'grad_norm': 4.223618507385254, 'learning_rate': 2.886666666666667e-05, 'epoch': 1.27}\n",
      "{'loss': 4.0113, 'grad_norm': 2.8613483905792236, 'learning_rate': 2.8733333333333335e-05, 'epoch': 1.28}\n",
      "{'loss': 3.9397, 'grad_norm': 3.262249708175659, 'learning_rate': 2.86e-05, 'epoch': 1.29}\n",
      "{'loss': 2.9523, 'grad_norm': 4.184933185577393, 'learning_rate': 2.846666666666667e-05, 'epoch': 1.3}\n",
      "{'loss': 3.4779, 'grad_norm': 10.599807739257812, 'learning_rate': 2.8333333333333335e-05, 'epoch': 1.3}\n",
      "{'loss': 2.7756, 'grad_norm': 5.066874027252197, 'learning_rate': 2.8199999999999998e-05, 'epoch': 1.31}\n",
      "{'loss': 3.5183, 'grad_norm': 4.109025478363037, 'learning_rate': 2.806666666666667e-05, 'epoch': 1.32}\n",
      "{'loss': 3.8077, 'grad_norm': 2.8594958782196045, 'learning_rate': 2.7933333333333332e-05, 'epoch': 1.33}\n",
      "{'loss': 3.7395, 'grad_norm': 5.556299209594727, 'learning_rate': 2.7800000000000005e-05, 'epoch': 1.34}\n",
      "{'loss': 2.9716, 'grad_norm': 3.9453749656677246, 'learning_rate': 2.7666666666666667e-05, 'epoch': 1.34}\n",
      "{'loss': 4.0883, 'grad_norm': 4.00990629196167, 'learning_rate': 2.7533333333333333e-05, 'epoch': 1.35}\n",
      "{'loss': 3.6303, 'grad_norm': 3.9311201572418213, 'learning_rate': 2.7400000000000002e-05, 'epoch': 1.36}\n",
      "{'loss': 4.0837, 'grad_norm': 4.2316412925720215, 'learning_rate': 2.7266666666666668e-05, 'epoch': 1.37}\n",
      "{'loss': 2.8974, 'grad_norm': 3.4580206871032715, 'learning_rate': 2.7133333333333333e-05, 'epoch': 1.38}\n",
      "{'loss': 3.9489, 'grad_norm': 3.203409433364868, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.38}\n",
      "{'loss': 2.6399, 'grad_norm': 3.619539976119995, 'learning_rate': 2.6866666666666668e-05, 'epoch': 1.39}\n",
      "{'loss': 3.8447, 'grad_norm': 3.3712849617004395, 'learning_rate': 2.6733333333333334e-05, 'epoch': 1.4}\n",
      "{'loss': 3.339, 'grad_norm': 3.3484981060028076, 'learning_rate': 2.6600000000000003e-05, 'epoch': 1.41}\n",
      "{'loss': 3.6849, 'grad_norm': 3.3682453632354736, 'learning_rate': 2.646666666666667e-05, 'epoch': 1.42}\n",
      "{'loss': 3.5214, 'grad_norm': 3.7484664916992188, 'learning_rate': 2.633333333333333e-05, 'epoch': 1.42}\n",
      "{'loss': 3.754, 'grad_norm': 4.205275535583496, 'learning_rate': 2.6200000000000003e-05, 'epoch': 1.43}\n",
      "{'loss': 3.5959, 'grad_norm': 3.2249596118927, 'learning_rate': 2.6066666666666666e-05, 'epoch': 1.44}\n",
      "{'loss': 2.9901, 'grad_norm': 3.350973129272461, 'learning_rate': 2.5933333333333338e-05, 'epoch': 1.45}\n",
      "{'loss': 3.4423, 'grad_norm': 4.0095367431640625, 'learning_rate': 2.58e-05, 'epoch': 1.46}\n",
      "{'loss': 2.8295, 'grad_norm': 4.569696426391602, 'learning_rate': 2.5666666666666666e-05, 'epoch': 1.46}\n",
      "{'loss': 3.2603, 'grad_norm': 4.1284589767456055, 'learning_rate': 2.553333333333334e-05, 'epoch': 1.47}\n",
      "{'loss': 4.2782, 'grad_norm': 3.4649908542633057, 'learning_rate': 2.54e-05, 'epoch': 1.48}\n",
      "{'loss': 3.2683, 'grad_norm': 3.5433454513549805, 'learning_rate': 2.5266666666666666e-05, 'epoch': 1.49}\n",
      "{'loss': 3.7121, 'grad_norm': 4.134460926055908, 'learning_rate': 2.5133333333333336e-05, 'epoch': 1.5}\n",
      "{'loss': 3.7872, 'grad_norm': 3.977100372314453, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n",
      "{'loss': 3.7987, 'grad_norm': 3.477853536605835, 'learning_rate': 2.486666666666667e-05, 'epoch': 1.51}\n",
      "{'loss': 3.8987, 'grad_norm': 6.555324077606201, 'learning_rate': 2.4733333333333333e-05, 'epoch': 1.52}\n",
      "{'loss': 4.0789, 'grad_norm': 3.688084602355957, 'learning_rate': 2.46e-05, 'epoch': 1.53}\n",
      "{'loss': 4.0585, 'grad_norm': 3.642843723297119, 'learning_rate': 2.4466666666666667e-05, 'epoch': 1.54}\n",
      "{'loss': 3.4629, 'grad_norm': 3.941500186920166, 'learning_rate': 2.4333333333333336e-05, 'epoch': 1.54}\n",
      "{'loss': 2.9269, 'grad_norm': 4.987463474273682, 'learning_rate': 2.4200000000000002e-05, 'epoch': 1.55}\n",
      "{'loss': 2.9922, 'grad_norm': 4.375977516174316, 'learning_rate': 2.4066666666666668e-05, 'epoch': 1.56}\n",
      "{'loss': 3.4767, 'grad_norm': 3.4839959144592285, 'learning_rate': 2.3933333333333337e-05, 'epoch': 1.57}\n",
      "{'loss': 2.9947, 'grad_norm': 2.5688564777374268, 'learning_rate': 2.38e-05, 'epoch': 1.58}\n",
      "{'loss': 3.4375, 'grad_norm': 2.5466420650482178, 'learning_rate': 2.3666666666666668e-05, 'epoch': 1.58}\n",
      "{'loss': 3.87, 'grad_norm': 2.6993424892425537, 'learning_rate': 2.3533333333333334e-05, 'epoch': 1.59}\n",
      "{'loss': 3.7491, 'grad_norm': 4.36948299407959, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.6}\n",
      "{'loss': 3.1598, 'grad_norm': 3.5830836296081543, 'learning_rate': 2.326666666666667e-05, 'epoch': 1.61}\n",
      "{'loss': 4.2351, 'grad_norm': 2.8945956230163574, 'learning_rate': 2.3133333333333334e-05, 'epoch': 1.62}\n",
      "{'loss': 4.2447, 'grad_norm': 4.9776411056518555, 'learning_rate': 2.3000000000000003e-05, 'epoch': 1.62}\n",
      "{'loss': 3.5236, 'grad_norm': 4.430478572845459, 'learning_rate': 2.2866666666666666e-05, 'epoch': 1.63}\n",
      "{'loss': 3.0599, 'grad_norm': 4.482173919677734, 'learning_rate': 2.2733333333333335e-05, 'epoch': 1.64}\n",
      "{'loss': 3.0425, 'grad_norm': 3.596445322036743, 'learning_rate': 2.26e-05, 'epoch': 1.65}\n",
      "{'loss': 3.0414, 'grad_norm': 2.7159461975097656, 'learning_rate': 2.2466666666666666e-05, 'epoch': 1.66}\n",
      "{'loss': 3.5406, 'grad_norm': 2.675727605819702, 'learning_rate': 2.2333333333333335e-05, 'epoch': 1.66}\n",
      "{'loss': 3.6272, 'grad_norm': 3.1705915927886963, 'learning_rate': 2.22e-05, 'epoch': 1.67}\n",
      "{'loss': 2.6512, 'grad_norm': 6.5850067138671875, 'learning_rate': 2.206666666666667e-05, 'epoch': 1.68}\n",
      "{'loss': 3.0488, 'grad_norm': 3.1327807903289795, 'learning_rate': 2.1933333333333332e-05, 'epoch': 1.69}\n",
      "{'loss': 3.461, 'grad_norm': 3.5215094089508057, 'learning_rate': 2.18e-05, 'epoch': 1.7}\n",
      "{'loss': 3.7991, 'grad_norm': 3.2528886795043945, 'learning_rate': 2.1666666666666667e-05, 'epoch': 1.7}\n",
      "{'loss': 3.0486, 'grad_norm': 5.690705299377441, 'learning_rate': 2.1533333333333333e-05, 'epoch': 1.71}\n",
      "{'loss': 3.3203, 'grad_norm': 2.9257569313049316, 'learning_rate': 2.1400000000000002e-05, 'epoch': 1.72}\n",
      "{'loss': 2.9439, 'grad_norm': 4.085443019866943, 'learning_rate': 2.1266666666666667e-05, 'epoch': 1.73}\n",
      "{'loss': 4.137, 'grad_norm': 3.2287659645080566, 'learning_rate': 2.1133333333333337e-05, 'epoch': 1.74}\n",
      "{'loss': 2.6887, 'grad_norm': 3.1282310485839844, 'learning_rate': 2.1e-05, 'epoch': 1.74}\n",
      "{'loss': 3.2451, 'grad_norm': 2.762990713119507, 'learning_rate': 2.0866666666666668e-05, 'epoch': 1.75}\n",
      "{'loss': 3.0712, 'grad_norm': 5.472644329071045, 'learning_rate': 2.0733333333333334e-05, 'epoch': 1.76}\n",
      "{'loss': 3.5916, 'grad_norm': 5.466951370239258, 'learning_rate': 2.06e-05, 'epoch': 1.77}\n",
      "{'loss': 3.777, 'grad_norm': 3.864325761795044, 'learning_rate': 2.046666666666667e-05, 'epoch': 1.78}\n",
      "{'loss': 3.307, 'grad_norm': 3.0216400623321533, 'learning_rate': 2.0333333333333334e-05, 'epoch': 1.78}\n",
      "{'loss': 2.994, 'grad_norm': 2.893334150314331, 'learning_rate': 2.0200000000000003e-05, 'epoch': 1.79}\n",
      "{'loss': 2.2279, 'grad_norm': 4.2216715812683105, 'learning_rate': 2.0066666666666665e-05, 'epoch': 1.8}\n",
      "{'loss': 2.7908, 'grad_norm': 4.295819282531738, 'learning_rate': 1.9933333333333334e-05, 'epoch': 1.81}\n",
      "{'loss': 3.7745, 'grad_norm': 3.089583396911621, 'learning_rate': 1.9800000000000004e-05, 'epoch': 1.82}\n",
      "{'loss': 2.9346, 'grad_norm': 3.8776111602783203, 'learning_rate': 1.9666666666666666e-05, 'epoch': 1.82}\n",
      "{'loss': 3.7299, 'grad_norm': 2.8443970680236816, 'learning_rate': 1.9533333333333335e-05, 'epoch': 1.83}\n",
      "{'loss': 2.8035, 'grad_norm': 3.915802001953125, 'learning_rate': 1.94e-05, 'epoch': 1.84}\n",
      "{'loss': 3.6789, 'grad_norm': 3.8393197059631348, 'learning_rate': 1.926666666666667e-05, 'epoch': 1.85}\n",
      "{'loss': 3.8058, 'grad_norm': 3.618288040161133, 'learning_rate': 1.9133333333333332e-05, 'epoch': 1.86}\n",
      "{'loss': 2.8892, 'grad_norm': 4.282606601715088, 'learning_rate': 1.9e-05, 'epoch': 1.86}\n",
      "{'loss': 3.5886, 'grad_norm': 3.4728007316589355, 'learning_rate': 1.886666666666667e-05, 'epoch': 1.87}\n",
      "{'loss': 3.8511, 'grad_norm': 3.875307559967041, 'learning_rate': 1.8733333333333332e-05, 'epoch': 1.88}\n",
      "{'loss': 3.5636, 'grad_norm': 2.786876916885376, 'learning_rate': 1.86e-05, 'epoch': 1.89}\n",
      "{'loss': 3.4599, 'grad_norm': 2.640634059906006, 'learning_rate': 1.8466666666666667e-05, 'epoch': 1.9}\n",
      "{'loss': 2.5629, 'grad_norm': 3.8474199771881104, 'learning_rate': 1.8333333333333333e-05, 'epoch': 1.9}\n",
      "{'loss': 3.4849, 'grad_norm': 4.3076276779174805, 'learning_rate': 1.8200000000000002e-05, 'epoch': 1.91}\n",
      "{'loss': 3.0207, 'grad_norm': 4.036571979522705, 'learning_rate': 1.8066666666666668e-05, 'epoch': 1.92}\n",
      "{'loss': 4.0895, 'grad_norm': 3.206125259399414, 'learning_rate': 1.7933333333333337e-05, 'epoch': 1.93}\n",
      "{'loss': 3.4089, 'grad_norm': 4.0670366287231445, 'learning_rate': 1.78e-05, 'epoch': 1.94}\n",
      "{'loss': 3.5241, 'grad_norm': 2.7411205768585205, 'learning_rate': 1.7666666666666668e-05, 'epoch': 1.94}\n",
      "{'loss': 3.2028, 'grad_norm': 2.8685901165008545, 'learning_rate': 1.7533333333333334e-05, 'epoch': 1.95}\n",
      "{'loss': 3.5771, 'grad_norm': 2.9096693992614746, 'learning_rate': 1.74e-05, 'epoch': 1.96}\n",
      "{'loss': 2.4978, 'grad_norm': 3.755679130554199, 'learning_rate': 1.726666666666667e-05, 'epoch': 1.97}\n",
      "{'loss': 3.1151, 'grad_norm': 4.169151306152344, 'learning_rate': 1.7133333333333334e-05, 'epoch': 1.98}\n",
      "{'loss': 2.8904, 'grad_norm': 4.066086292266846, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.98}\n",
      "{'loss': 3.4835, 'grad_norm': 3.5685818195343018, 'learning_rate': 1.6866666666666666e-05, 'epoch': 1.99}\n",
      "{'loss': 3.1842, 'grad_norm': 3.804216146469116, 'learning_rate': 1.6733333333333335e-05, 'epoch': 2.0}\n",
      " 67%|███████████████████████████▎             | 500/750 [00:45<00:16, 15.53it/s]/opt/anaconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "{'loss': 3.9303, 'grad_norm': 4.40393590927124, 'learning_rate': 1.66e-05, 'epoch': 2.01}\n",
      "{'loss': 2.7792, 'grad_norm': 3.1120853424072266, 'learning_rate': 1.6466666666666666e-05, 'epoch': 2.02}\n",
      "{'loss': 3.2746, 'grad_norm': 3.0271339416503906, 'learning_rate': 1.6333333333333335e-05, 'epoch': 2.02}\n",
      "{'loss': 2.8362, 'grad_norm': 2.7102584838867188, 'learning_rate': 1.62e-05, 'epoch': 2.03}\n",
      "{'loss': 2.4479, 'grad_norm': 4.414417266845703, 'learning_rate': 1.606666666666667e-05, 'epoch': 2.04}\n",
      "{'loss': 3.4153, 'grad_norm': 3.1028082370758057, 'learning_rate': 1.5933333333333332e-05, 'epoch': 2.05}\n",
      "{'loss': 3.5765, 'grad_norm': 3.6763503551483154, 'learning_rate': 1.58e-05, 'epoch': 2.06}\n",
      "{'loss': 2.8146, 'grad_norm': 3.474700927734375, 'learning_rate': 1.5666666666666667e-05, 'epoch': 2.06}\n",
      "{'loss': 3.3422, 'grad_norm': 3.4563164710998535, 'learning_rate': 1.5533333333333333e-05, 'epoch': 2.07}\n",
      "{'loss': 3.3054, 'grad_norm': 2.5958263874053955, 'learning_rate': 1.54e-05, 'epoch': 2.08}\n",
      "{'loss': 2.6823, 'grad_norm': 2.566150665283203, 'learning_rate': 1.5266666666666667e-05, 'epoch': 2.09}\n",
      "{'loss': 2.5139, 'grad_norm': 4.192453861236572, 'learning_rate': 1.5133333333333333e-05, 'epoch': 2.1}\n",
      "{'loss': 3.25, 'grad_norm': 2.96331787109375, 'learning_rate': 1.5e-05, 'epoch': 2.1}\n",
      "{'loss': 3.1185, 'grad_norm': 2.4359450340270996, 'learning_rate': 1.4866666666666668e-05, 'epoch': 2.11}\n",
      "{'loss': 3.8419, 'grad_norm': 3.881985664367676, 'learning_rate': 1.4733333333333335e-05, 'epoch': 2.12}\n",
      "{'loss': 3.0587, 'grad_norm': 3.7777256965637207, 'learning_rate': 1.4599999999999999e-05, 'epoch': 2.13}\n",
      "{'loss': 2.9967, 'grad_norm': 3.2309563159942627, 'learning_rate': 1.4466666666666667e-05, 'epoch': 2.14}\n",
      "{'loss': 3.1972, 'grad_norm': 3.4813618659973145, 'learning_rate': 1.4333333333333334e-05, 'epoch': 2.14}\n",
      "{'loss': 3.4778, 'grad_norm': 4.762787342071533, 'learning_rate': 1.42e-05, 'epoch': 2.15}\n",
      "{'loss': 3.1715, 'grad_norm': 2.671084403991699, 'learning_rate': 1.4066666666666667e-05, 'epoch': 2.16}\n",
      "{'loss': 2.8801, 'grad_norm': 3.8308775424957275, 'learning_rate': 1.3933333333333334e-05, 'epoch': 2.17}\n",
      "{'loss': 3.4623, 'grad_norm': 4.363301753997803, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.18}\n",
      "{'loss': 3.3043, 'grad_norm': 3.22051739692688, 'learning_rate': 1.3666666666666666e-05, 'epoch': 2.18}\n",
      "{'loss': 3.2708, 'grad_norm': 3.557215929031372, 'learning_rate': 1.3533333333333335e-05, 'epoch': 2.19}\n",
      "{'loss': 3.4045, 'grad_norm': 2.688896417617798, 'learning_rate': 1.3400000000000002e-05, 'epoch': 2.2}\n",
      "{'loss': 3.328, 'grad_norm': 2.978940725326538, 'learning_rate': 1.3266666666666666e-05, 'epoch': 2.21}\n",
      "{'loss': 4.024, 'grad_norm': 3.1149017810821533, 'learning_rate': 1.3133333333333334e-05, 'epoch': 2.22}\n",
      "{'loss': 3.1234, 'grad_norm': 2.648610830307007, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.22}\n",
      "{'loss': 2.4523, 'grad_norm': 3.621821403503418, 'learning_rate': 1.2866666666666668e-05, 'epoch': 2.23}\n",
      "{'loss': 3.2717, 'grad_norm': 3.215651273727417, 'learning_rate': 1.2733333333333334e-05, 'epoch': 2.24}\n",
      "{'loss': 3.3191, 'grad_norm': 3.8377315998077393, 'learning_rate': 1.2600000000000001e-05, 'epoch': 2.25}\n",
      "{'loss': 3.4182, 'grad_norm': 3.153513193130493, 'learning_rate': 1.2466666666666667e-05, 'epoch': 2.26}\n",
      "{'loss': 3.1865, 'grad_norm': 3.6220247745513916, 'learning_rate': 1.2333333333333334e-05, 'epoch': 2.26}\n",
      "{'loss': 3.168, 'grad_norm': 3.46114182472229, 'learning_rate': 1.22e-05, 'epoch': 2.27}\n",
      "{'loss': 3.935, 'grad_norm': 3.9382474422454834, 'learning_rate': 1.2066666666666667e-05, 'epoch': 2.28}\n",
      "{'loss': 2.9092, 'grad_norm': 2.9694437980651855, 'learning_rate': 1.1933333333333333e-05, 'epoch': 2.29}\n",
      "{'loss': 4.0496, 'grad_norm': 3.92645263671875, 'learning_rate': 1.18e-05, 'epoch': 2.3}\n",
      "{'loss': 2.5048, 'grad_norm': 2.7445480823516846, 'learning_rate': 1.1666666666666668e-05, 'epoch': 2.3}\n",
      "{'loss': 3.846, 'grad_norm': 3.4548826217651367, 'learning_rate': 1.1533333333333334e-05, 'epoch': 2.31}\n",
      "{'loss': 2.6192, 'grad_norm': 2.622739553451538, 'learning_rate': 1.1400000000000001e-05, 'epoch': 2.32}\n",
      "{'loss': 3.3753, 'grad_norm': 3.5555081367492676, 'learning_rate': 1.1266666666666667e-05, 'epoch': 2.33}\n",
      "{'loss': 3.408, 'grad_norm': 3.165006637573242, 'learning_rate': 1.1133333333333334e-05, 'epoch': 2.34}\n",
      "{'loss': 2.4082, 'grad_norm': 4.402035713195801, 'learning_rate': 1.1000000000000001e-05, 'epoch': 2.34}\n",
      "{'loss': 2.85, 'grad_norm': 3.1690733432769775, 'learning_rate': 1.0866666666666667e-05, 'epoch': 2.35}\n",
      "{'loss': 3.0133, 'grad_norm': 3.169689655303955, 'learning_rate': 1.0733333333333334e-05, 'epoch': 2.36}\n",
      "{'loss': 3.1488, 'grad_norm': 3.3025221824645996, 'learning_rate': 1.06e-05, 'epoch': 2.37}\n",
      "{'loss': 3.1653, 'grad_norm': 3.673022985458374, 'learning_rate': 1.0466666666666668e-05, 'epoch': 2.38}\n",
      "{'loss': 3.7637, 'grad_norm': 4.105615615844727, 'learning_rate': 1.0333333333333333e-05, 'epoch': 2.38}\n",
      "{'loss': 2.7799, 'grad_norm': 2.6731481552124023, 'learning_rate': 1.02e-05, 'epoch': 2.39}\n",
      "{'loss': 3.2917, 'grad_norm': 3.976839780807495, 'learning_rate': 1.0066666666666668e-05, 'epoch': 2.4}\n",
      "{'loss': 3.7846, 'grad_norm': 2.696526288986206, 'learning_rate': 9.933333333333334e-06, 'epoch': 2.41}\n",
      "{'loss': 3.444, 'grad_norm': 3.5021698474884033, 'learning_rate': 9.800000000000001e-06, 'epoch': 2.42}\n",
      "{'loss': 3.1087, 'grad_norm': 3.47395396232605, 'learning_rate': 9.666666666666667e-06, 'epoch': 2.42}\n",
      "{'loss': 3.908, 'grad_norm': 3.217163324356079, 'learning_rate': 9.533333333333334e-06, 'epoch': 2.43}\n",
      "{'loss': 2.613, 'grad_norm': 3.5536088943481445, 'learning_rate': 9.4e-06, 'epoch': 2.44}\n",
      "{'loss': 3.7223, 'grad_norm': 2.9166362285614014, 'learning_rate': 9.266666666666667e-06, 'epoch': 2.45}\n",
      "{'loss': 2.8449, 'grad_norm': 3.0107996463775635, 'learning_rate': 9.133333333333335e-06, 'epoch': 2.46}\n",
      "{'loss': 3.8569, 'grad_norm': 5.399485111236572, 'learning_rate': 9e-06, 'epoch': 2.46}\n",
      "{'loss': 3.1482, 'grad_norm': 2.7407948970794678, 'learning_rate': 8.866666666666668e-06, 'epoch': 2.47}\n",
      "{'loss': 3.5174, 'grad_norm': 3.3971617221832275, 'learning_rate': 8.733333333333333e-06, 'epoch': 2.48}\n",
      "{'loss': 3.1794, 'grad_norm': 4.166758060455322, 'learning_rate': 8.599999999999999e-06, 'epoch': 2.49}\n",
      "{'loss': 2.07, 'grad_norm': 5.882287979125977, 'learning_rate': 8.466666666666666e-06, 'epoch': 2.5}\n",
      "{'loss': 3.2146, 'grad_norm': 3.437760353088379, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n",
      "{'loss': 3.0996, 'grad_norm': 3.0629539489746094, 'learning_rate': 8.200000000000001e-06, 'epoch': 2.51}\n",
      "{'loss': 3.3087, 'grad_norm': 3.1020851135253906, 'learning_rate': 8.066666666666667e-06, 'epoch': 2.52}\n",
      "{'loss': 2.7539, 'grad_norm': 3.6198747158050537, 'learning_rate': 7.933333333333334e-06, 'epoch': 2.53}\n",
      "{'loss': 2.2995, 'grad_norm': 4.566399097442627, 'learning_rate': 7.8e-06, 'epoch': 2.54}\n",
      "{'loss': 3.7669, 'grad_norm': 4.322717666625977, 'learning_rate': 7.666666666666667e-06, 'epoch': 2.54}\n",
      "{'loss': 2.8578, 'grad_norm': 4.265532493591309, 'learning_rate': 7.533333333333334e-06, 'epoch': 2.55}\n",
      "{'loss': 3.4429, 'grad_norm': 2.8327841758728027, 'learning_rate': 7.4e-06, 'epoch': 2.56}\n",
      "{'loss': 3.6006, 'grad_norm': 2.3538224697113037, 'learning_rate': 7.266666666666668e-06, 'epoch': 2.57}\n",
      "{'loss': 2.9286, 'grad_norm': 3.2588393688201904, 'learning_rate': 7.133333333333333e-06, 'epoch': 2.58}\n",
      "{'loss': 3.2849, 'grad_norm': 3.259064197540283, 'learning_rate': 7.000000000000001e-06, 'epoch': 2.58}\n",
      "{'loss': 3.5555, 'grad_norm': 3.263137102127075, 'learning_rate': 6.866666666666667e-06, 'epoch': 2.59}\n",
      "{'loss': 3.3968, 'grad_norm': 3.8120687007904053, 'learning_rate': 6.733333333333333e-06, 'epoch': 2.6}\n",
      "{'loss': 3.0086, 'grad_norm': 3.1233227252960205, 'learning_rate': 6.6e-06, 'epoch': 2.61}\n",
      "{'loss': 4.0199, 'grad_norm': 3.8598077297210693, 'learning_rate': 6.466666666666667e-06, 'epoch': 2.62}\n",
      "{'loss': 3.186, 'grad_norm': 3.267876625061035, 'learning_rate': 6.333333333333334e-06, 'epoch': 2.62}\n",
      "{'loss': 3.7495, 'grad_norm': 3.297196626663208, 'learning_rate': 6.2e-06, 'epoch': 2.63}\n",
      "{'loss': 3.2415, 'grad_norm': 4.0623779296875, 'learning_rate': 6.066666666666667e-06, 'epoch': 2.64}\n",
      "{'loss': 2.4503, 'grad_norm': 4.2118096351623535, 'learning_rate': 5.933333333333334e-06, 'epoch': 2.65}\n",
      "{'loss': 3.5039, 'grad_norm': 3.7244374752044678, 'learning_rate': 5.8e-06, 'epoch': 2.66}\n",
      "{'loss': 3.6403, 'grad_norm': 2.5392773151397705, 'learning_rate': 5.666666666666667e-06, 'epoch': 2.66}\n",
      "{'loss': 3.6387, 'grad_norm': 3.478970527648926, 'learning_rate': 5.5333333333333334e-06, 'epoch': 2.67}\n",
      "{'loss': 3.0764, 'grad_norm': 4.117633819580078, 'learning_rate': 5.4e-06, 'epoch': 2.68}\n",
      "{'loss': 4.0927, 'grad_norm': 3.578125476837158, 'learning_rate': 5.266666666666667e-06, 'epoch': 2.69}\n",
      "{'loss': 4.0659, 'grad_norm': 3.83762788772583, 'learning_rate': 5.133333333333334e-06, 'epoch': 2.7}\n",
      "{'loss': 3.4496, 'grad_norm': 2.6440012454986572, 'learning_rate': 5e-06, 'epoch': 2.7}\n",
      "{'loss': 2.7235, 'grad_norm': 4.252806186676025, 'learning_rate': 4.866666666666667e-06, 'epoch': 2.71}\n",
      "{'loss': 3.1915, 'grad_norm': 2.9026498794555664, 'learning_rate': 4.7333333333333335e-06, 'epoch': 2.72}\n",
      "{'loss': 2.9552, 'grad_norm': 3.658710479736328, 'learning_rate': 4.6e-06, 'epoch': 2.73}\n",
      "{'loss': 3.5936, 'grad_norm': 3.0511653423309326, 'learning_rate': 4.4666666666666665e-06, 'epoch': 2.74}\n",
      "{'loss': 3.0843, 'grad_norm': 3.5844483375549316, 'learning_rate': 4.333333333333334e-06, 'epoch': 2.74}\n",
      "{'loss': 3.5533, 'grad_norm': 3.8906471729278564, 'learning_rate': 4.2000000000000004e-06, 'epoch': 2.75}\n",
      "{'loss': 3.7101, 'grad_norm': 3.6045219898223877, 'learning_rate': 4.066666666666666e-06, 'epoch': 2.76}\n",
      "{'loss': 3.444, 'grad_norm': 4.277681827545166, 'learning_rate': 3.9333333333333335e-06, 'epoch': 2.77}\n",
      "{'loss': 3.0406, 'grad_norm': 3.3956854343414307, 'learning_rate': 3.8e-06, 'epoch': 2.78}\n",
      "{'loss': 3.4087, 'grad_norm': 2.5652053356170654, 'learning_rate': 3.666666666666667e-06, 'epoch': 2.78}\n",
      "{'loss': 3.4064, 'grad_norm': 3.3116049766540527, 'learning_rate': 3.5333333333333335e-06, 'epoch': 2.79}\n",
      "{'loss': 2.7059, 'grad_norm': 3.4963221549987793, 'learning_rate': 3.4000000000000005e-06, 'epoch': 2.8}\n",
      "{'loss': 3.168, 'grad_norm': 3.5778439044952393, 'learning_rate': 3.2666666666666666e-06, 'epoch': 2.81}\n",
      "{'loss': 2.8372, 'grad_norm': 4.686122894287109, 'learning_rate': 3.133333333333333e-06, 'epoch': 2.82}\n",
      "{'loss': 2.7902, 'grad_norm': 3.207657814025879, 'learning_rate': 3e-06, 'epoch': 2.82}\n",
      "{'loss': 3.243, 'grad_norm': 3.7864785194396973, 'learning_rate': 2.8666666666666666e-06, 'epoch': 2.83}\n",
      "{'loss': 3.3175, 'grad_norm': 2.855234384536743, 'learning_rate': 2.7333333333333336e-06, 'epoch': 2.84}\n",
      "{'loss': 3.3645, 'grad_norm': 3.07999587059021, 'learning_rate': 2.6e-06, 'epoch': 2.85}\n",
      "{'loss': 3.5211, 'grad_norm': 2.686736583709717, 'learning_rate': 2.4666666666666666e-06, 'epoch': 2.86}\n",
      "{'loss': 2.6767, 'grad_norm': 3.7485339641571045, 'learning_rate': 2.3333333333333336e-06, 'epoch': 2.86}\n",
      "{'loss': 3.3428, 'grad_norm': 2.7826740741729736, 'learning_rate': 2.2e-06, 'epoch': 2.87}\n",
      "{'loss': 2.9237, 'grad_norm': 3.6005337238311768, 'learning_rate': 2.0666666666666666e-06, 'epoch': 2.88}\n",
      "{'loss': 3.2925, 'grad_norm': 4.641232013702393, 'learning_rate': 1.9333333333333336e-06, 'epoch': 2.89}\n",
      "{'loss': 2.9129, 'grad_norm': 3.4997942447662354, 'learning_rate': 1.8e-06, 'epoch': 2.9}\n",
      "{'loss': 4.0059, 'grad_norm': 2.4875872135162354, 'learning_rate': 1.6666666666666667e-06, 'epoch': 2.9}\n",
      "{'loss': 2.6853, 'grad_norm': 3.8934061527252197, 'learning_rate': 1.5333333333333334e-06, 'epoch': 2.91}\n",
      "{'loss': 3.3366, 'grad_norm': 2.5882179737091064, 'learning_rate': 1.4000000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 2.7448, 'grad_norm': 4.67000675201416, 'learning_rate': 1.2666666666666667e-06, 'epoch': 2.93}\n",
      "{'loss': 2.6891, 'grad_norm': 3.4194743633270264, 'learning_rate': 1.1333333333333334e-06, 'epoch': 2.94}\n",
      "{'loss': 2.5716, 'grad_norm': 3.644306182861328, 'learning_rate': 1.0000000000000002e-06, 'epoch': 2.94}\n",
      "{'loss': 3.7505, 'grad_norm': 4.8311052322387695, 'learning_rate': 8.666666666666667e-07, 'epoch': 2.95}\n",
      "{'loss': 3.1001, 'grad_norm': 4.357489585876465, 'learning_rate': 7.333333333333333e-07, 'epoch': 2.96}\n",
      "{'loss': 3.1634, 'grad_norm': 4.119487762451172, 'learning_rate': 6.000000000000001e-07, 'epoch': 2.97}\n",
      "{'loss': 3.9213, 'grad_norm': 4.5204973220825195, 'learning_rate': 4.666666666666667e-07, 'epoch': 2.98}\n",
      "{'loss': 2.4522, 'grad_norm': 2.8578221797943115, 'learning_rate': 3.3333333333333335e-07, 'epoch': 2.98}\n",
      "{'loss': 3.0803, 'grad_norm': 2.9366631507873535, 'learning_rate': 2.0000000000000002e-07, 'epoch': 2.99}\n",
      "{'loss': 2.6338, 'grad_norm': 3.5553677082061768, 'learning_rate': 6.666666666666667e-08, 'epoch': 3.0}\n",
      "{'train_runtime': 66.8338, 'train_samples_per_second': 22.444, 'train_steps_per_second': 11.222, 'train_loss': 3.883937051773071, 'epoch': 3.0}\n",
      "100%|█████████████████████████████████████████| 750/750 [01:06<00:00, 11.22it/s]\n",
      "   ✓ Training complete!\n",
      "\n",
      "6. Saving adapters...\n",
      "   ✓ Saved to ./finance_lora_adapters\n",
      "\n",
      "7. Testing fine-tuned model...\n",
      "\n",
      "   Q: What is a stock?\n",
      "   A: The company is worth $1.6 billion (U.S. dollars) in the fourth quarter of 2015, up from the same period a year ago. The company has a net profit of $2.9 billion (US$\n",
      "\n",
      "   Q: How do bonds work?\n",
      "   A: In the first quarter of 2012, the total value of the company rose to $1.6 billion, up 0.2% from the same period a year earlier. The company also increased its share of shares to $2.5\n",
      "\n",
      "   Q: Explain portfolio diversification in one sentence.\n",
      "   A: The net worth of the company rose by 2.5% in the first quarter of this year compared to the same period a year ago, according to a report released on Monday. The net worth for the company increased by 1.2\n",
      "\n",
      "   Q: What is the risk of long-term government bonds?\n",
      "   A: The value of the bonds rose to €1.2 billion in the first quarter of 2016, up from €1 billion in 2015. The value of shares in the bonds fell to €3.5 billion, down from €2.\n",
      "\n",
      "   Q: Why do companies pay dividends?\n",
      "   A: The value of the shares in the company rose by 2.5% in the first half of this year compared to the same period a year ago, according to a new report. According to the report, the company reported net profit of\n",
      "\n",
      "   Q: How does inflation affect bond prices?\n",
      "   A: In the first quarter of 2012, the value of the euro rose to $1.6 billion, compared with a year earlier, according to data from the European Central Bank (ECB) and the European Commission (EEC). The\n"
     ]
    }
   ],
   "source": [
    "!python finance_lora.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5972b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  MCP SERVER: Finance Tools\n",
      "======================================================================\n",
      "\n",
      "Available Tools:\n",
      "  1. get_stock_price(symbol) - Real stock prices\n",
      "  2. scrape_finance_news(topic) - Finance news scraping\n",
      "  3. calculate_investment(initial, rate, years) - Investment math\n",
      "\n",
      "Starting MCP server...\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/IPython/utils/_process_posix.py:156\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m child\u001b[38;5;241m.\u001b[39mexpect_list(patterns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_timeout)\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exp\u001b[38;5;241m.\u001b[39mexpect_loop(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m spawn\u001b[38;5;241m.\u001b[39mread_nonblocking(spawn\u001b[38;5;241m.\u001b[39mmaxread, timeout)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m select(timeout):\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m select_ignore_interrupts([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_fd], [], [], timeout)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m select\u001b[38;5;241m.\u001b[39mselect(iwtd, owtd, ewtd, timeout)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython finance_mcp_server.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_expand(cmd, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/IPython/utils/_process_posix.py:167\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    162\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     child\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pexpect/pty_spawn.py:578\u001b[0m, in \u001b[0;36mspawn.sendline\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Wraps send(), sending string ``s`` to child process, with\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m``os.linesep`` automatically appended. Returns number of bytes\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03mwritten.  Only a limited number of bytes may be sent for each\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03mline in the default terminal mode, see docstring of :meth:`send`.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    577\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coerce_send_string(s)\n\u001b[0;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(s \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinesep)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pexpect/pty_spawn.py:569\u001b[0m, in \u001b[0;36mspawn.send\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log(s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    568\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder\u001b[38;5;241m.\u001b[39mencode(s, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_fd, b)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "!python finance_mcp_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252ff55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
